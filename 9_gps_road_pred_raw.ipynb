{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0ee5d1d-c478-4b63-9df5-f77906c6256b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lmy/7_model_gps_road.py\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.functional as f\n",
    "from torch.nn import Parameter\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import torch.optim as optim\n",
    "from torch.nn.utils.rnn import pad_sequence \n",
    "import itertools\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "from prettytable import PrettyTable\n",
    "import datetime\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import time\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")  # Ignore all warnings\n",
    "import math\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import progressbar\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "from scipy.stats import skew, kurtosis\n",
    "from numpy.lib.stride_tricks import as_strided as stride\n",
    "from geopy.distance import geodesic\n",
    "import _pickle as cPickle\n",
    "import argparse\n",
    "import random\n",
    "from utils import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "print('lmy/7_model_gps_road.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9c116d3-fda5-4dca-badc-38565499a29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames =get_filenames()\n",
    "\n",
    "# %%\n",
    "args = get_parser()\n",
    "args.transformer = 1\n",
    "args.gpu = 1\n",
    "args.STAT_NET_input_road = np.array([ 8, 11, 20, 21, 27,  6])#train_data.stat_data.loc[:,get_road_name()].max().values+1#最大值加1\n",
    "\n",
    "args.device = 'cuda:{}'.format(args.gpu) if (args.gpu>=0) & torch.cuda.is_available() else 'cpu'\n",
    "#args.now = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S:%f==') #时间\n",
    "args.model_save = '/DATA2/lvxiaoling/limengyuan/SHL2023/save/models2023-06-20 00_09_42_502543==.pth'\n",
    "\n",
    "args.CONV_SENSORS_input_dim = 12\n",
    "args.CONV_GEO_num_feat = 6\n",
    "args.STAT_NET_input_sensors = 195\n",
    "args.STAT_NET_input_geo = 26\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b7d49d8-5d31-4e21-a6f6-efb2ab9323a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class  dset(Dataset):\n",
    "    def __init__(self, data_sensor,data_gps,stat_data):\n",
    "        super(dset, self).__init__()\n",
    "        self.data_sensor = data_sensor\n",
    "        self.data_gps = data_gps\n",
    "        self.stat_data = stat_data\n",
    "        self.name_dict = {name:i for i,name in enumerate(stat_data)}\n",
    "        self.stat_sensors = [self.name_dict[i] for i in get_sensors_name()]\n",
    "        self.stat_gps = [self.name_dict[i] for i in get_gps_name()]\n",
    "        self.stat_road = [self.name_dict[i] for i in get_road_name()]\n",
    "    def __len__(self):\n",
    "        return len(self.data_gps)\n",
    "    def  __getitem__(self, i):\n",
    "        stat_value = self.stat_data[self.stat_data['idx'].isin(self.data_gps[i][args.L1-1:,-3])].values\n",
    "        if len(stat_value)!= len(self.data_gps[i][args.L1-1:,-3]):\n",
    "            print(i)\n",
    "        return torch.tensor(self.data_sensor[i]),torch.tensor(self.data_gps[i]),torch.tensor(stat_value[:,self.stat_sensors]),torch.tensor(stat_value[:,self.stat_gps]),torch.tensor(stat_value[:,self.stat_road]).long()\n",
    "    #返回的10分钟内的数据\n",
    "    #data_sensor,data_gps,label,idx\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 加载数据\n",
    "\n",
    "# %%\n",
    "def collate_batch(batch):\n",
    "    data_sensor_list,data_gps_list,lengths,stat_list1,stat_list2,stat_list3 =  [], [],[],[], [],[]\n",
    "    batch.sort(key=lambda x: len(x[0]), reverse=True)#按照长度的大小进行排序\n",
    "    for (data_sensor_,data_gps_,stat_list1_i,stat_list2_i,stat_list3_i) in batch:\n",
    "\n",
    "\n",
    "\n",
    "        data_sensor_list.append(data_sensor_)\n",
    "        data_gps_list.append(data_gps_)\n",
    "        \n",
    "        lengths.append(data_gps_.shape[0])\n",
    "        stat_list1.append(stat_list1_i)\n",
    "        stat_list2.append(stat_list2_i)\n",
    "        stat_list3.append(stat_list3_i)\n",
    "\n",
    "    data_sensor_list = pad_sequence(data_sensor_list, padding_value=args.pad_value, batch_first=True)#进行填充，每个batch中的句子需要有相同的长度\n",
    "    data_gps_list = pad_sequence(data_gps_list, padding_value=args.pad_value, batch_first=True)#进行填充，每个batch中的句子需要有相同的长度\n",
    "    \n",
    "    stat_list1 = pad_sequence(stat_list1, padding_value=args.pad_value, batch_first=True)#进行填充，每个batch中的句子需要有相同的长度\n",
    "    stat_list2 = pad_sequence(stat_list2, padding_value=args.pad_value, batch_first=True)#进行填充，每个batch中的句子需要有相同的长度\n",
    "    stat_list3 = pad_sequence(stat_list3, padding_value=args.pad_value, batch_first=True)#进行填充，每个batch中的句子需要有相同的长度\n",
    "    roads = []\n",
    "    for i in range(6):\n",
    "        road_i = stat_list3[:,:,[i]]\n",
    "        road_i[road_i==args.pad_value] = args.STAT_NET_input_road[i]\n",
    "        roads.append(road_i)\n",
    "    stat_list3 = torch.cat(roads,dim=-1)\n",
    "\n",
    "        #stat_list3[:,:,i][stat_list3[:,:,i]==args.pad_value] = args.STAT_NET_input_road[i]\n",
    "\n",
    "    label =  torch.tensor(data_gps_list)[:,:,-4].long()\n",
    "    label[label>0] = label[label>0]-1\n",
    "    #data_sensor,data_gps,stat_sensors,stat_gps,stat_road, label,idx,trip_idx, lengths in train_dataloader\n",
    "    return data_sensor_list.float(),data_gps_list[:,:,:-4].float(),\\\n",
    "        stat_list1.float(),stat_list2.float(),stat_list3.long(),\\\n",
    "        label,torch.tensor(data_gps_list)[:,:,-3].long(),torch.tensor(data_gps_list)[:,:,-2].long(), lengths\n",
    "        #'label','idx','trajectory_id','label_idx'\\\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52ea8987-20e2-475d-9937-c65b9b2929c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/DATA2/lvxiaoling/limengyuan/SHL2023/save/models2023-06-20 00_09_42_502543==.pth\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# %%\n",
    "class CONV_SENSORS(nn.Module):\n",
    "    def __init__(self,input_dim=3, num_filter = 64,kernel_size = 500, stride=100):\n",
    "        super(CONV_SENSORS,self).__init__()\n",
    "        self.conv = nn.Conv1d(input_dim, num_filter, kernel_size, stride = stride)\n",
    "\n",
    "    def forward(self,data_sensor):# traj:batch_size*seq_len*17\n",
    "        # 地理卷积\n",
    "        data_sensor = data_sensor.permute(0,2,1)#batch_size,seq_len,num\n",
    "        data_sensor = F.elu(self.conv(data_sensor)).permute(0,2,1)# L*seq_len'*num_filter\n",
    "        return data_sensor\n",
    "\n",
    "\n",
    "# %%\n",
    "class CONV_GEO(nn.Module):\n",
    "    def __init__(self,kernel_size=5,num_filter=64,num_feat = 6):\n",
    "        super(CONV_GEO,self).__init__()\n",
    "        self.process_coords = nn.Linear(2,16)\n",
    "        self.conv1 = nn.Conv1d(16,num_filter,kernel_size)\n",
    "        self.conv2 = nn.Conv1d(num_feat,num_filter,kernel_size)\n",
    "\n",
    "    def forward(self,data_gps):# traj:batch_size*seq_len*17\n",
    "        # 地理卷积\n",
    "        \n",
    "        lngs_lats = data_gps[:,:,:2] #batch_size*seq_len*2\n",
    "        locs1 = torch.tanh(self.process_coords(lngs_lats))# batch_size*seq_len*16\n",
    "        locs1 =locs1.permute(0,2,1)# batch_size*16*seq_len\n",
    "        conv_locs1 = F.elu(self.conv1(locs1)).permute(0,2,1)# L*seq_len'*num_filter\n",
    "        \n",
    "        # 特征卷积\n",
    "        features = data_gps[:,:,2:]# batch_size*seq_len*14\n",
    "        locs2 = features.permute(0,2,1)# batch_size*14*seq_len\n",
    "        conv_locs2 = F.elu(self.conv2(locs2)).permute(0,2,1)# L*seq_len'*num_filter\n",
    "        \n",
    "        return torch.concat([conv_locs1,conv_locs2],dim=2)#地理、特征、时间\n",
    "        ## L*seq_len'*num_filter\n",
    "\n",
    "# %%\n",
    "class STAT_NET(nn.Module):\n",
    "    def __init__(self,args=args,\n",
    "                 input_road = [3,4,5,6,7,8],road_embedding =16, \n",
    "                 input_sensors=125,sensors_embedding = 64,\n",
    "                 input_geo=125,geo_embedding = 64):\n",
    "        super(STAT_NET, self).__init__()\n",
    "        self.pad_value = args.pad_value\n",
    "        self.args = args\n",
    "        self.input_road = input_road\n",
    "        self.emb = nn.ModuleList([nn.Embedding(i+1,road_embedding,padding_idx=i)    for  i in input_road])\n",
    "        self.fc_sensors = nn.Linear(input_sensors,sensors_embedding)\n",
    "        self.fc_geo = nn.Linear(input_geo,geo_embedding)\n",
    "        #embedding层\n",
    "        \n",
    "\n",
    "    def forward(self, stat_sensors,stat_gps,stat_road):\n",
    "        stat_sensors = self.fc_sensors(stat_sensors)\n",
    "        stat_gps = self.fc_geo(stat_gps)\n",
    "\n",
    "        roads = []\n",
    "        for i,layer in enumerate(self.emb):\n",
    "            road_i = stat_road[:,:,i]#batch_size,sqe_len,feat_num\n",
    "            #road_i[road_i==args.pad_value] = self.input_road[i]\n",
    "            road_i = layer(road_i)\n",
    "            roads.append(road_i)\n",
    "        roads = torch.cat(roads,dim=-1)\n",
    "        return torch.cat([stat_gps,roads],dim=-1)\n",
    "\n",
    "# %%\n",
    "class BILSTM(torch.nn.Module):\n",
    "    def __init__(self,args=args,input_dim=64+128, d_model = 128,out_dim=8):\n",
    "        super(BILSTM, self).__init__()\n",
    "        self.pad_value = args.pad_value\n",
    "        self.args = args\n",
    "        #embedding层\n",
    "        self.lstm = nn.LSTM(input_dim,d_model//2, num_layers = args.lstm_layer, bidirectional = True,\n",
    "                                dropout=args.dropout, batch_first=True)\n",
    "        self.projection = nn.Linear(d_model, out_dim)\n",
    "\n",
    "    def forward(self, x, lengths):\n",
    "        lengths = torch.tensor(lengths)-(self.args.L1-1)\n",
    "        packed_embedded = nn.utils.rnn.pack_padded_sequence(x, lengths, batch_first=True)        \n",
    "        packed_output, (hidden, cell) = self.lstm(packed_embedded)#lstm层\n",
    "        # hidden = [n layers *2, batch size, hidden dim]最后一个step的hidden\n",
    "        # cell = [n layers * 2, batch size, hidden dim]最终一个step的cell\n",
    "        x, output_lengths = nn.utils.rnn.pad_packed_sequence(packed_output, batch_first=True)\n",
    "        x = self.projection(x)\n",
    "        return x\n",
    "if args.transformer:\n",
    "    class BILSTM(torch.nn.Module):\n",
    "        def __init__(self,args=args,input_dim=64+128, d_model = 128,out_dim=8):\n",
    "            super(BILSTM, self).__init__()\n",
    "            self.pad_value = args.pad_value\n",
    "            self.args = args\n",
    "            #embedding层\n",
    "            self.lstm = nn.LSTM(input_dim,d_model//2, num_layers = args.lstm_layer, bidirectional = True,\n",
    "                                    dropout=args.dropout, batch_first=True)\n",
    "            self.encoder_layer = nn.TransformerEncoderLayer(d_model * args.nheads, args.nheads, args.ff_size, args.dropout, batch_first=True)\n",
    "            self.encoder = nn.TransformerEncoder(self.encoder_layer, args.n_layers)\n",
    "            self.fc = nn.Linear(d_model * args.nheads, d_model)\n",
    "\n",
    "            self.projection = nn.Linear(d_model, out_dim)\n",
    "\n",
    "        def forward(self, x, lengths):\n",
    "            lengths = torch.tensor(lengths)-(self.args.L1-1)\n",
    "            packed_embedded = nn.utils.rnn.pack_padded_sequence(x, lengths, batch_first=True)        \n",
    "            packed_output, (hidden, cell) = self.lstm(packed_embedded)#lstm层\n",
    "            # hidden = [n layers *2, batch size, hidden dim]最后一个step的hidden\n",
    "            # cell = [n layers * 2, batch size, hidden dim]最终一个step的cell\n",
    "            x, output_lengths = nn.utils.rnn.pad_packed_sequence(packed_output, batch_first=True)\n",
    "            mask = self.get_mask(lengths,x.shape[0])\n",
    "            x = self.encoder(x.repeat(1, 1, self.args.nheads), src_key_padding_mask=mask)\n",
    "            x = self.fc(x)\n",
    "            x = self.projection(x)\n",
    "\n",
    "\n",
    "            return x\n",
    "        def get_mask(self,sentence_lengths,batch_len):\n",
    "            # 计算最大句子长度\n",
    "            max_length = max(sentence_lengths)\n",
    "\n",
    "            # 创建一个零填充的张量，大小为(batch_size, max_length)\n",
    "            src_key_padding_mask = torch.zeros((batch_len, max_length), dtype=torch.bool)\n",
    "\n",
    "            # 对每个句子进行遍历，根据句子长度进行填充\n",
    "            for i, length in enumerate(sentence_lengths):\n",
    "                src_key_padding_mask[i, :length] = 1\n",
    "\n",
    "# %%\n",
    "if False:\n",
    "    data_sensor,data_gps,stat_sensors,stat_gps,stat_road, label,idx,trip_idx, length = next(iter(train_loader))\n",
    "\n",
    "    m1 = CONV_SENSORS(input_dim=args.CONV_SENSORS_input_dim, num_filter =args.num_filter)\n",
    "    r1 = m1(data_sensor)\n",
    "    m2 = CONV_GEO(num_feat = args.CONV_GEO_num_feat,num_filter =args.num_filter)\n",
    "    r2 = m2(data_gps)\n",
    "    m3 = STAT_NET(  input_road = args.STAT_NET_input_road,road_embedding =args.STAT_NET_road_embedding, \n",
    "                    input_sensors=args.STAT_NET_input_sensors,sensors_embedding = args.STAT_NET_sensors_embedding,\n",
    "                    input_geo=args.STAT_NET_input_geo,geo_embedding = args.STAT_NET_geo_embedding)\n",
    "    r3 = m3(stat_sensors,stat_gps,stat_road)\n",
    "    r = torch.cat([r1,r2,r3],dim=-1)\n",
    "\n",
    "    m3 = BILSTM(input_dim=3*args.num_filter +args.STAT_NET_geo_embedding+len( args.STAT_NET_input_road)*args.STAT_NET_road_embedding,args=args)\n",
    "    r4 = m3(r,length)\n",
    "\n",
    "\n",
    "def evaluate(model_s,model_g,model_stat,model,loss_fn,train_dataloader):\n",
    "    model_s.eval()\n",
    "    model_g.eval()\n",
    "    model_stat.eval()\n",
    "    model.eval()\n",
    "\n",
    "    \n",
    "    losses = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data_sensor,data_gps,stat_sensors,stat_gps,stat_road, label,idx,trip_idx, lengths in train_dataloader:\n",
    "            data_sensor = data_sensor.to(args.device)\n",
    "            data_gps = data_gps.to(args.device)\n",
    "            stat_sensors,stat_gps,stat_road = stat_sensors.to(args.device),stat_gps.to(args.device),stat_road.to(args.device)\n",
    "            label = label.to(args.device)[:,(args.L1-1):]\n",
    "\n",
    "            output_s = model_s(data_sensor)\n",
    "            output_g = model_g(data_gps)\n",
    "            output_stat = model_stat(stat_sensors,stat_gps,stat_road)\n",
    "            out = model(torch.cat([output_s,output_g,output_stat],dim=-1),lengths)\n",
    "\n",
    "            \n",
    "            loss = loss_fn( out.reshape(-1, out.shape[-1]), label.reshape(-1))\n",
    "           \n",
    "            losses += loss.item() \n",
    "            \n",
    "            mask = label ==args.pad_value\n",
    "            pred = torch.argmax(out, dim=2)\n",
    "            correct +=  (pred ==label ).masked_fill(mask,0).sum().item() / (~mask).sum()\n",
    "            \n",
    "    model_s.train()\n",
    "    model_g.train()\n",
    "    model_stat.train()\n",
    "    model.train()\n",
    "    return losses / len(train_dataloader),correct/len(train_dataloader)\n",
    "\n",
    "\n",
    "# %%\n",
    "model_s = CONV_SENSORS(input_dim=args.CONV_SENSORS_input_dim, num_filter =args.num_filter).to(args.device)\n",
    "model_g = CONV_GEO(num_feat = args.CONV_GEO_num_feat,num_filter =args.num_filter).to(args.device)\n",
    "model_stat = STAT_NET(input_road = args.STAT_NET_input_road,road_embedding =args.STAT_NET_road_embedding, \n",
    "                 input_sensors=args.STAT_NET_input_sensors,sensors_embedding = args.STAT_NET_sensors_embedding,\n",
    "                 input_geo=args.STAT_NET_input_geo,geo_embedding = args.STAT_NET_geo_embedding).to(args.device)\n",
    "model = BILSTM(input_dim=3*args.num_filter+args.STAT_NET_geo_embedding+len( args.STAT_NET_input_road)*args.STAT_NET_road_embedding,args=args).to(args.device)\n",
    "\n",
    "if args.weightloss:\n",
    "    weight = torch.tensor([1.0048, 1.0022, 2.9012, 1.0453, 0.7708, 0.8641, 0.7827, 1.0274]).to(args.device)\n",
    "    criterion  = nn.CrossEntropyLoss(ignore_index=args.pad_value,weight=weight)\n",
    "else:\n",
    "    criterion  = nn.CrossEntropyLoss(ignore_index=args.pad_value)\n",
    "\n",
    "\n",
    "#args.model_save = '/DATA1/EvolveGCN/limengyuan/datas/models/models2023-06-16 09:35:17:728874==.pth'\n",
    "checkpoint = torch.load( args.model_save)\n",
    "model_s.load_state_dict(checkpoint['model_s'])\n",
    "model_g.load_state_dict(checkpoint['model_g'])\n",
    "model_stat.load_state_dict(checkpoint['model_stat'])\n",
    "model.load_state_dict(checkpoint['model'])\n",
    "print(args.model_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4818097f-1374-43eb-833d-86393e82aa11",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def prediction_val(model_s,model_g,model_stat,model,loss_fn,train_dataloader):\n",
    "    model_s.eval()\n",
    "    model_g.eval()\n",
    "    model_stat.eval()\n",
    "    model.eval()\n",
    "\n",
    "\n",
    "    losses = 0\n",
    "    correct = 0\n",
    "    preds = []\n",
    "    idxs = []\n",
    "    labels = []\n",
    "    outs= []\n",
    "    trip_idxs = []\n",
    "    with torch.no_grad():\n",
    "        for data_sensor,data_gps,stat_sensors,stat_gps,stat_road, label,idx,trip_idx, lengths in train_dataloader:\n",
    "            data_sensor = data_sensor.to(args.device)\n",
    "            data_gps = data_gps.to(args.device)\n",
    "            stat_sensors,stat_gps,stat_road = stat_sensors.to(args.device),stat_gps.to(args.device),stat_road.to(args.device)\n",
    "            label = label.to(args.device)[:,(args.L1-1):]\n",
    "\n",
    "            output_s = model_s(data_sensor)\n",
    "            output_g = model_g(data_gps)\n",
    "            output_stat = model_stat(stat_sensors,stat_gps,stat_road)\n",
    "            out = model(torch.cat([output_s,output_g,output_stat],dim=-1),lengths)\n",
    "\n",
    "            loss = loss_fn( out.reshape(-1, out.shape[-1]), label.reshape(-1))\n",
    "\n",
    "            losses += loss.item() \n",
    "\n",
    "            mask = label ==args.pad_value\n",
    "            pred = torch.argmax(out, dim=2)\n",
    "            correct +=  (pred ==label ).masked_fill(mask,0).sum().item() / (~mask).sum()\n",
    "\n",
    "            preds.append(pred)\n",
    "            idxs.append(idx[:,(args.L1-1):])\n",
    "            labels.append(label)\n",
    "            outs.append(F.softmax(out,dim=-1))\n",
    "            trip_idxs.append(trip_idx)\n",
    "\n",
    "    model_s.train()\n",
    "    model_g.train()\n",
    "    model.train()\n",
    "    model_stat.train()\n",
    "    return torch.cat(preds),torch.cat(idxs),torch.cat(trip_idxs),torch.cat(labels),torch.cat(outs),losses / len(train_dataloader),correct/len(train_dataloader)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "13357ccf-c66b-4828-b7b6-fdb0920c396d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss 1.4505567252635956 test acc 0.8304504752159119\n",
      "acc_pred 0.8444934504825776\n",
      "acc_outs 0.8534261966739478\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Still       0.88      0.88      0.88     29676\n",
      "        Walk       0.93      0.90      0.92     25879\n",
      "         Run       1.00      1.00      1.00      2754\n",
      "        Bike       0.98      0.65      0.78     12001\n",
      "         Car       0.91      0.53      0.67     20438\n",
      "         Bus       0.41      0.91      0.57      9138\n",
      "       Train       0.97      1.00      0.98     21763\n",
      "      Subway       0.93      0.98      0.95     21644\n",
      "\n",
      "    accuracy                           0.85    143293\n",
      "   macro avg       0.88      0.86      0.84    143293\n",
      "weighted avg       0.89      0.85      0.86    143293\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def val_dataset(loc='Hand'):\n",
    "\n",
    "\n",
    "    train_hand = pd.read_pickle('/DATA2/lvxiaoling/limengyuan/SHL2023/valid/Hand/raw_data.pkl')\n",
    "    stat_data = pd.read_pickle('/DATA2/lvxiaoling/limengyuan/SHL2023/valid/Hand/data.pkl').fillna(0).drop_duplicates(keep='first')   \n",
    "\n",
    "    data_x = np.arange(len(train_hand[0]))#trajectory id\n",
    "    data_y = [int(i[0][0,-4]) for i in train_hand[1]]\n",
    "    val_sensor = [j for i in data_x for j in train_hand[0][i]]\n",
    "    val_gps = [j for i in data_x for j in train_hand[1][i]]\n",
    "    val_data = dset(val_sensor,val_gps,stat_data)\n",
    "\n",
    "\n",
    "    test_loader1 = torch.utils.data.DataLoader(\n",
    "        dataset=val_data,\n",
    "        batch_size=args.batch_size,\n",
    "        shuffle=False,\n",
    "        collate_fn=collate_batch,\n",
    "        num_workers = args.num_workers\n",
    "        )\n",
    "    return test_loader1\n",
    "val_loader = val_dataset(loc='Hand')\n",
    "\n",
    "\n",
    "test_loss,test_acc  = evaluate(model_s,model_g,model_stat,model, criterion, val_loader)\n",
    "print('test loss',test_loss,'test acc',test_acc.item())\n",
    "\n",
    "\n",
    "preds,idxs,trip_idxs,labels,outs,_,_ = prediction_val(model_s,model_g,model_stat,model, criterion, val_loader)\n",
    "\n",
    "\n",
    "idxs_1 = idxs.reshape(-1,1).cpu().numpy()\n",
    "labels_1 = labels.reshape(-1,1).cpu().numpy()\n",
    "preds_1 = preds.reshape(-1,1).cpu().numpy()\n",
    "outs_1 = outs.reshape(-1,outs.shape[2]).cpu().numpy()\n",
    "\n",
    "results = pd.DataFrame(np.concatenate((idxs_1,labels_1,preds_1,outs_1), axis =1))\n",
    "results.columns = ['idx','label_true','preds'] + [i for i in range(8)]\n",
    "\n",
    "\n",
    "#results_new = results.groupby('id')[[i for i in range(8)]].mean()\n",
    "results_new = results.groupby('idx')[['label_true']].min().reset_index().astype(int)\n",
    "results_new['preds'] = results.groupby('idx')[['preds']].agg(lambda x: x.value_counts().index[0]).values.astype(int)\n",
    "results_new[['out_{}'.format(i) for i in range(8)]] = results.groupby('idx')[[i for i in range(8)]].mean().values\n",
    "results_new['out_pred'] = results_new[['out_{}'.format(i) for i in range(8)]].idxmax(axis=1).str.replace('out_','').astype(int).values\n",
    "\n",
    "\n",
    "results_new = results_new[results_new['idx']>=0]\n",
    "print('acc_pred',(results_new['label_true']==results_new['preds']).mean())\n",
    "print('acc_outs',(results_new['label_true']==results_new['out_pred']).mean())\n",
    "\n",
    "\n",
    "y_true = results_new['label_true']\n",
    "y_pred = results_new['out_pred']\n",
    "label_sort = ['Still','Walk','Run','Bike','Car','Bus','Train', 'Subway']\n",
    "print(classification_report(y_true, y_pred, target_names = label_sort))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a8d7d39a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8436713110362108\n"
     ]
    }
   ],
   "source": [
    "f1 = f1_score(y_true, y_pred, average='macro')\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ae14ad05",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_new.to_pickle('/DATA2/lvxiaoling/limengyuan/SHL2023/out_put2/val_dl1.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a736bffd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f2884e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6838922",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf72f8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5687d929-96b6-4b50-b5d9-3c736e0b0f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.read_pickle('/DATA2/lvxiaoling/limengyuan/SHL2023/valid/Hand/data_m.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "523b0cb5-fad3-4e6f-8b0e-e4f8a32a7c2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>label_true</th>\n",
       "      <th>preds</th>\n",
       "      <th>out_0</th>\n",
       "      <th>out_1</th>\n",
       "      <th>out_2</th>\n",
       "      <th>out_3</th>\n",
       "      <th>out_4</th>\n",
       "      <th>out_5</th>\n",
       "      <th>out_6</th>\n",
       "      <th>out_7</th>\n",
       "      <th>out_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>972</th>\n",
       "      <td>98151959</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.547380e-10</td>\n",
       "      <td>0.000370</td>\n",
       "      <td>9.996122e-01</td>\n",
       "      <td>1.731336e-05</td>\n",
       "      <td>1.341374e-08</td>\n",
       "      <td>2.966969e-07</td>\n",
       "      <td>1.673522e-11</td>\n",
       "      <td>7.841782e-12</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>973</th>\n",
       "      <td>98152059</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3.389006e-10</td>\n",
       "      <td>0.000549</td>\n",
       "      <td>9.994211e-01</td>\n",
       "      <td>2.928923e-05</td>\n",
       "      <td>2.669635e-08</td>\n",
       "      <td>6.596539e-07</td>\n",
       "      <td>2.407421e-11</td>\n",
       "      <td>1.278901e-11</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>974</th>\n",
       "      <td>98152159</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4.987610e-10</td>\n",
       "      <td>0.000695</td>\n",
       "      <td>9.992657e-01</td>\n",
       "      <td>3.794068e-05</td>\n",
       "      <td>3.526685e-08</td>\n",
       "      <td>9.240382e-07</td>\n",
       "      <td>2.776567e-11</td>\n",
       "      <td>1.677911e-11</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>975</th>\n",
       "      <td>98152259</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5.620661e-10</td>\n",
       "      <td>0.000792</td>\n",
       "      <td>9.991636e-01</td>\n",
       "      <td>4.345069e-05</td>\n",
       "      <td>3.571139e-08</td>\n",
       "      <td>9.661060e-07</td>\n",
       "      <td>2.688788e-11</td>\n",
       "      <td>1.879061e-11</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>976</th>\n",
       "      <td>98152359</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5.550348e-10</td>\n",
       "      <td>0.000912</td>\n",
       "      <td>9.990358e-01</td>\n",
       "      <td>5.154762e-05</td>\n",
       "      <td>3.158042e-08</td>\n",
       "      <td>8.877526e-07</td>\n",
       "      <td>2.306973e-11</td>\n",
       "      <td>2.003461e-11</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130332</th>\n",
       "      <td>111147513</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.034779e-03</td>\n",
       "      <td>0.998303</td>\n",
       "      <td>6.971605e-07</td>\n",
       "      <td>2.582975e-07</td>\n",
       "      <td>2.135911e-11</td>\n",
       "      <td>4.311542e-07</td>\n",
       "      <td>6.604673e-04</td>\n",
       "      <td>7.224384e-08</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130333</th>\n",
       "      <td>111147613</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.211804e-03</td>\n",
       "      <td>0.997825</td>\n",
       "      <td>8.366143e-07</td>\n",
       "      <td>3.193990e-07</td>\n",
       "      <td>3.017924e-11</td>\n",
       "      <td>7.285955e-07</td>\n",
       "      <td>9.614481e-04</td>\n",
       "      <td>1.002015e-07</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130334</th>\n",
       "      <td>111147713</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.349535e-03</td>\n",
       "      <td>0.997686</td>\n",
       "      <td>6.885070e-07</td>\n",
       "      <td>3.103495e-07</td>\n",
       "      <td>3.803373e-11</td>\n",
       "      <td>9.884053e-07</td>\n",
       "      <td>9.627640e-04</td>\n",
       "      <td>1.088594e-07</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130335</th>\n",
       "      <td>111147813</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.326025e-03</td>\n",
       "      <td>0.997628</td>\n",
       "      <td>6.285812e-07</td>\n",
       "      <td>2.818232e-07</td>\n",
       "      <td>4.027456e-11</td>\n",
       "      <td>1.195491e-06</td>\n",
       "      <td>1.043889e-03</td>\n",
       "      <td>1.257443e-07</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130336</th>\n",
       "      <td>111147913</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.336596e-03</td>\n",
       "      <td>0.997418</td>\n",
       "      <td>5.704523e-07</td>\n",
       "      <td>2.808744e-07</td>\n",
       "      <td>3.630424e-11</td>\n",
       "      <td>1.632506e-06</td>\n",
       "      <td>1.243128e-03</td>\n",
       "      <td>1.533284e-07</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26037 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              idx  label_true  preds         out_0     out_1         out_2  \\\n",
       "972      98151959           2      2  1.547380e-10  0.000370  9.996122e-01   \n",
       "973      98152059           2      2  3.389006e-10  0.000549  9.994211e-01   \n",
       "974      98152159           2      2  4.987610e-10  0.000695  9.992657e-01   \n",
       "975      98152259           2      2  5.620661e-10  0.000792  9.991636e-01   \n",
       "976      98152359           2      2  5.550348e-10  0.000912  9.990358e-01   \n",
       "...           ...         ...    ...           ...       ...           ...   \n",
       "130332  111147513           0      1  1.034779e-03  0.998303  6.971605e-07   \n",
       "130333  111147613           0      1  1.211804e-03  0.997825  8.366143e-07   \n",
       "130334  111147713           0      1  1.349535e-03  0.997686  6.885070e-07   \n",
       "130335  111147813           0      1  1.326025e-03  0.997628  6.285812e-07   \n",
       "130336  111147913           0      1  1.336596e-03  0.997418  5.704523e-07   \n",
       "\n",
       "               out_3         out_4         out_5         out_6         out_7  \\\n",
       "972     1.731336e-05  1.341374e-08  2.966969e-07  1.673522e-11  7.841782e-12   \n",
       "973     2.928923e-05  2.669635e-08  6.596539e-07  2.407421e-11  1.278901e-11   \n",
       "974     3.794068e-05  3.526685e-08  9.240382e-07  2.776567e-11  1.677911e-11   \n",
       "975     4.345069e-05  3.571139e-08  9.661060e-07  2.688788e-11  1.879061e-11   \n",
       "976     5.154762e-05  3.158042e-08  8.877526e-07  2.306973e-11  2.003461e-11   \n",
       "...              ...           ...           ...           ...           ...   \n",
       "130332  2.582975e-07  2.135911e-11  4.311542e-07  6.604673e-04  7.224384e-08   \n",
       "130333  3.193990e-07  3.017924e-11  7.285955e-07  9.614481e-04  1.002015e-07   \n",
       "130334  3.103495e-07  3.803373e-11  9.884053e-07  9.627640e-04  1.088594e-07   \n",
       "130335  2.818232e-07  4.027456e-11  1.195491e-06  1.043889e-03  1.257443e-07   \n",
       "130336  2.808744e-07  3.630424e-11  1.632506e-06  1.243128e-03  1.533284e-07   \n",
       "\n",
       "        out_pred  \n",
       "972            2  \n",
       "973            2  \n",
       "974            2  \n",
       "975            2  \n",
       "976            2  \n",
       "...          ...  \n",
       "130332         1  \n",
       "130333         1  \n",
       "130334         1  \n",
       "130335         1  \n",
       "130336         1  \n",
       "\n",
       "[26037 rows x 12 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = results_new[results_new['idx'].isin(a['idx'])]\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "93ce747b-a7fe-4a88-b593-fe31a94f030e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Still       1.00      0.94      0.97      3661\n",
      "        Walk       0.94      0.92      0.93      3743\n",
      "         Run       1.00      1.00      1.00       310\n",
      "        Bike       0.86      1.00      0.93      1840\n",
      "         Car       1.00      0.91      0.95      6710\n",
      "         Bus       0.98      1.00      0.99       236\n",
      "       Train       0.93      1.00      0.96      7370\n",
      "      Subway       1.00      1.00      1.00      2167\n",
      "\n",
      "    accuracy                           0.96     26037\n",
      "   macro avg       0.96      0.97      0.97     26037\n",
      "weighted avg       0.96      0.96      0.96     26037\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(m['label_true'].values, m['out_pred'].values, target_names = label_sort))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b1e7fc89-9681-4adc-99f9-8e4df556b0dc",
   "metadata": {},
   "source": [
    "# 加载原始的训练集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9b3822aa-6dc5-4640-b10f-9fdf7503dac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss 0.0697939423548162 test acc 0.9926158785820007\n"
     ]
    }
   ],
   "source": [
    "def val_dataset(loc='Hand'):\n",
    "\n",
    "\n",
    "    train_hand = cPickle.load(open('/DATA2/lvxiaoling/limengyuan/SHL2023/train/{}/raw_data_m.pkl'.format(loc),'rb'))\n",
    "    stat_data = cPickle.load(open('/DATA2/lvxiaoling/limengyuan/SHL2023/train/{}/data_m.pkl'.format(loc),'rb')).fillna(0).drop_duplicates(keep='first')   \n",
    "\n",
    "    data_x = np.arange(len(train_hand[0]))#trajectory id\n",
    "    data_y = [int(i[0][0,-4]) for i in train_hand[1]]\n",
    "    val_sensor = [j for i in data_x for j in train_hand[0][i]]\n",
    "    val_gps = [j for i in data_x for j in train_hand[1][i]]\n",
    "    val_data = dset(val_sensor,val_gps,stat_data)\n",
    "\n",
    "\n",
    "    test_loader1 = torch.utils.data.DataLoader(\n",
    "        dataset=val_data,\n",
    "        batch_size=args.batch_size,\n",
    "        shuffle=False,\n",
    "        collate_fn=collate_batch,\n",
    "        num_workers = args.num_workers\n",
    "        )\n",
    "    return test_loader1\n",
    "val_loader = val_dataset(loc='Hand')\n",
    "\n",
    "\n",
    "test_loss,test_acc  = evaluate(model_s,model_g,model_stat,model, criterion, val_loader)\n",
    "print('test loss',test_loss,'test acc',test_acc.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5fc3673b-a4c3-462e-b5cb-73d2803edcf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc_outs 0.992761942141327\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Still       1.00      0.99      0.99    120940\n",
      "        Walk       1.00      0.99      1.00    117175\n",
      "         Run       1.00      0.95      0.97     35805\n",
      "        Bike       0.98      1.00      0.99    110793\n",
      "         Car       1.00      0.99      1.00    146300\n",
      "         Bus       0.99      1.00      1.00    121841\n",
      "       Train       0.99      0.99      0.99    147554\n",
      "      Subway       0.99      0.99      0.99    116827\n",
      "\n",
      "    accuracy                           0.99    917235\n",
      "   macro avg       0.99      0.99      0.99    917235\n",
      "weighted avg       0.99      0.99      0.99    917235\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds,idxs,trip_idxs,labels,outs,_,_ = prediction_val(model_s,model_g,model_stat,model, criterion, val_loader)\n",
    "\n",
    "idxs_1 = idxs.reshape(-1,1).cpu().numpy()\n",
    "labels_1 = labels.reshape(-1,1).cpu().numpy()\n",
    "preds_1 = preds.reshape(-1,1).cpu().numpy()\n",
    "outs_1 = outs.reshape(-1,outs.shape[2]).cpu().numpy()\n",
    "\n",
    "results = pd.DataFrame(np.concatenate((idxs_1,labels_1,preds_1,outs_1), axis =1))\n",
    "results.columns = ['idx','label_true','preds'] + [i for i in range(8)]\n",
    "\n",
    "\n",
    "#results_new = results.groupby('id')[[i for i in range(8)]].mean()\n",
    "results_new = results.groupby('idx')[['label_true']].min().reset_index().astype(int)\n",
    "results_new[['out_{}'.format(i) for i in range(8)]] = results.groupby('idx')[[i for i in range(8)]].mean().values\n",
    "results_new['out_pred'] = results_new[['out_{}'.format(i) for i in range(8)]].idxmax(axis=1).str.replace('out_','').astype(int).values\n",
    "\n",
    "\n",
    "results_new = results_new[results_new['idx']>=0]\n",
    "results_new.to_pickle('/DATA2/lvxiaoling/limengyuan/SHL2023/out_put/train_dl1.pkl')\n",
    "print('acc_outs',(results_new['label_true']==results_new['out_pred']).mean())\n",
    "\n",
    "\n",
    "y_true = results_new['label_true']\n",
    "y_pred = results_new['out_pred']\n",
    "label_sort = ['Still','Walk','Run','Bike','Car','Bus','Train', 'Subway']\n",
    "print(classification_report(y_true, y_pred, target_names = label_sort))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0cfb5f9b-d56a-4777-96f1-6ef4840c1710",
   "metadata": {},
   "source": [
    "# 加载原始验证集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e4f415f6-cbb6-41d8-b0e8-c45ad8c6ab37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss 0.43757653289607595 test acc 0.92779940366745\n"
     ]
    }
   ],
   "source": [
    "def val_dataset(loc='Hand'):\n",
    "\n",
    "\n",
    "    train_hand = cPickle.load(open('/DATA2/lvxiaoling/limengyuan/SHL2023/valid/{}/raw_data_m.pkl'.format(loc),'rb'))\n",
    "    stat_data = cPickle.load(open('/DATA2/lvxiaoling/limengyuan/SHL2023/valid/{}/data_m.pkl'.format(loc),'rb')).fillna(0).drop_duplicates(keep='first')   \n",
    "\n",
    "    data_x = np.arange(len(train_hand[0]))#trajectory id\n",
    "    data_y = [int(i[0][0,-4]) for i in train_hand[1]]\n",
    "    val_sensor = [j for i in data_x for j in train_hand[0][i]]\n",
    "    val_gps = [j for i in data_x for j in train_hand[1][i]]\n",
    "    val_data = dset(val_sensor,val_gps,stat_data)\n",
    "\n",
    "\n",
    "    test_loader1 = torch.utils.data.DataLoader(\n",
    "        dataset=val_data,\n",
    "        batch_size=args.batch_size,\n",
    "        shuffle=False,\n",
    "        collate_fn=collate_batch,\n",
    "        num_workers = args.num_workers\n",
    "        )\n",
    "    return test_loader1\n",
    "val_loader = val_dataset(loc='Hand')\n",
    "\n",
    "\n",
    "test_loss,test_acc  = evaluate(model_s,model_g,model_stat,model, criterion, val_loader)\n",
    "print('test loss',test_loss,'test acc',test_acc.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "752265ed-f946-422d-afa4-66e2315985d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc_outs 0.9339100669358528\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Still       1.00      0.95      0.98     30422\n",
      "        Walk       0.98      0.98      0.98     30804\n",
      "         Run       1.00      0.79      0.88      9000\n",
      "        Bike       0.87      0.99      0.93     18040\n",
      "         Car       0.87      0.92      0.89     32418\n",
      "         Bus       0.93      0.83      0.87     28475\n",
      "       Train       0.98      0.95      0.96     30079\n",
      "      Subway       0.88      0.99      0.93     24091\n",
      "\n",
      "    accuracy                           0.93    203329\n",
      "   macro avg       0.94      0.92      0.93    203329\n",
      "weighted avg       0.94      0.93      0.93    203329\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds,idxs,trip_idxs,labels,outs,_,_ = prediction_val(model_s,model_g,model_stat,model, criterion, val_loader)\n",
    "\n",
    "idxs_1 = idxs.reshape(-1,1).cpu().numpy()\n",
    "labels_1 = labels.reshape(-1,1).cpu().numpy()\n",
    "preds_1 = preds.reshape(-1,1).cpu().numpy()\n",
    "outs_1 = outs.reshape(-1,outs.shape[2]).cpu().numpy()\n",
    "\n",
    "results = pd.DataFrame(np.concatenate((idxs_1,labels_1,preds_1,outs_1), axis =1))\n",
    "results.columns = ['idx','label_true','preds'] + [i for i in range(8)]\n",
    "\n",
    "\n",
    "#results_new = results.groupby('id')[[i for i in range(8)]].mean()\n",
    "results_new = results.groupby('idx')[['label_true']].min().reset_index().astype(int)\n",
    "results_new[['out_{}'.format(i) for i in range(8)]] = results.groupby('idx')[[i for i in range(8)]].mean().values\n",
    "results_new['out_pred'] = results_new[['out_{}'.format(i) for i in range(8)]].idxmax(axis=1).str.replace('out_','').astype(int).values\n",
    "\n",
    "\n",
    "results_new = results_new[results_new['idx']>=0]\n",
    "print('acc_outs',(results_new['label_true']==results_new['out_pred']).mean())\n",
    "results_new.to_pickle('/DATA2/lvxiaoling/limengyuan/SHL2023/out_put/val_dl1.pkl')\n",
    "\n",
    "\n",
    "y_true = results_new['label_true']\n",
    "y_pred = results_new['out_pred']\n",
    "label_sort = ['Still','Walk','Run','Bike','Car','Bus','Train', 'Subway']\n",
    "print(classification_report(y_true, y_pred, target_names = label_sort))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a14cbce7-37ca-43cc-b15e-450b95349ee1",
   "metadata": {},
   "source": [
    "# 加载原始测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f053b20f-f561-4e76-9380-5fa210f3832c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss 0.0 test acc nan\n"
     ]
    }
   ],
   "source": [
    "def val_dataset(loc='Hand'):\n",
    "\n",
    "\n",
    "    train_hand = cPickle.load(open('/DATA2/lvxiaoling/limengyuan/SHL2023/test/raw_data.pkl'.format(loc),'rb'))\n",
    "    stat_data = cPickle.load(open('/DATA2/lvxiaoling/limengyuan/SHL2023/test/data.pkl'.format(loc),'rb')).fillna(0).drop_duplicates(keep='first')   \n",
    "\n",
    "    data_x = np.arange(len(train_hand[0]))#trajectory id\n",
    "    data_y = [int(i[0][0,-4]) for i in train_hand[1]]\n",
    "    val_sensor = [j for i in data_x for j in train_hand[0][i]]\n",
    "    val_gps = [j for i in data_x for j in train_hand[1][i]]\n",
    "    val_data = dset(val_sensor,val_gps,stat_data)\n",
    "\n",
    "\n",
    "    test_loader1 = torch.utils.data.DataLoader(\n",
    "        dataset=val_data,\n",
    "        batch_size=args.batch_size,\n",
    "        shuffle=False,\n",
    "        collate_fn=collate_batch,\n",
    "        num_workers = args.num_workers\n",
    "        )\n",
    "    return test_loader1\n",
    "val_loader = val_dataset(loc='Hand')\n",
    "\n",
    "\n",
    "test_loss,test_acc  = evaluate(model_s,model_g,model_stat,model, criterion, val_loader)\n",
    "print('test loss',test_loss,'test acc',test_acc.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ea40d431-173f-41cc-a47a-8bcbc2229ba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc_outs 0.0\n"
     ]
    }
   ],
   "source": [
    "preds,idxs,trip_idxs,labels,outs,_,_ = prediction_val(model_s,model_g,model_stat,model, criterion, val_loader)\n",
    "\n",
    "idxs_1 = idxs.reshape(-1,1).cpu().numpy()\n",
    "labels_1 = labels.reshape(-1,1).cpu().numpy()\n",
    "preds_1 = preds.reshape(-1,1).cpu().numpy()\n",
    "outs_1 = outs.reshape(-1,outs.shape[2]).cpu().numpy()\n",
    "\n",
    "results = pd.DataFrame(np.concatenate((idxs_1,labels_1,preds_1,outs_1), axis =1))\n",
    "results.columns = ['idx','label_true','preds'] + [i for i in range(8)]\n",
    "\n",
    "\n",
    "#results_new = results.groupby('id')[[i for i in range(8)]].mean()\n",
    "results_new = results.groupby('idx')[['label_true']].min().reset_index().astype(int)\n",
    "results_new[['out_{}'.format(i) for i in range(8)]] = results.groupby('idx')[[i for i in range(8)]].mean().values\n",
    "results_new['out_pred'] = results_new[['out_{}'.format(i) for i in range(8)]].idxmax(axis=1).str.replace('out_','').astype(int).values\n",
    "\n",
    "\n",
    "results_new = results_new[results_new['idx']>=0]\n",
    "results_new.to_pickle('/DATA2/lvxiaoling/limengyuan/SHL2023/out_put/test_dl1.pkl')\n",
    "\n",
    "print('acc_outs',(results_new['label_true']==results_new['out_pred']).mean())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "edccd4b3-0ada-4c92-b716-7fcecd995115",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = 60000\n",
    "results_new['out_pred'].values[m:m+200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "548e9371",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>label_true</th>\n",
       "      <th>out_0</th>\n",
       "      <th>out_1</th>\n",
       "      <th>out_2</th>\n",
       "      <th>out_3</th>\n",
       "      <th>out_4</th>\n",
       "      <th>out_5</th>\n",
       "      <th>out_6</th>\n",
       "      <th>out_7</th>\n",
       "      <th>out_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>112448921</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.004899</td>\n",
       "      <td>0.021637</td>\n",
       "      <td>0.111022</td>\n",
       "      <td>2.193493e-03</td>\n",
       "      <td>0.860165</td>\n",
       "      <td>1.620770e-06</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>112449021</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.003213</td>\n",
       "      <td>0.016925</td>\n",
       "      <td>0.061346</td>\n",
       "      <td>2.321039e-03</td>\n",
       "      <td>0.916116</td>\n",
       "      <td>1.789388e-06</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>112449121</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.003039</td>\n",
       "      <td>0.016792</td>\n",
       "      <td>0.044756</td>\n",
       "      <td>2.357378e-03</td>\n",
       "      <td>0.932966</td>\n",
       "      <td>1.707474e-06</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>112449221</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.003815</td>\n",
       "      <td>0.016265</td>\n",
       "      <td>0.042099</td>\n",
       "      <td>1.511095e-03</td>\n",
       "      <td>0.936162</td>\n",
       "      <td>1.590745e-06</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>112449321</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.004872</td>\n",
       "      <td>0.014967</td>\n",
       "      <td>0.050168</td>\n",
       "      <td>1.806122e-03</td>\n",
       "      <td>0.927962</td>\n",
       "      <td>1.498758e-06</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462266</th>\n",
       "      <td>158833732</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0.076385</td>\n",
       "      <td>0.455255</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.467187</td>\n",
       "      <td>6.948846e-08</td>\n",
       "      <td>0.001108</td>\n",
       "      <td>1.411081e-08</td>\n",
       "      <td>0.000063</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462267</th>\n",
       "      <td>158833832</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0.071031</td>\n",
       "      <td>0.464753</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.463062</td>\n",
       "      <td>6.628539e-08</td>\n",
       "      <td>0.001092</td>\n",
       "      <td>1.382692e-08</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462268</th>\n",
       "      <td>158833932</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0.067352</td>\n",
       "      <td>0.465470</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.465978</td>\n",
       "      <td>6.614611e-08</td>\n",
       "      <td>0.001137</td>\n",
       "      <td>1.437202e-08</td>\n",
       "      <td>0.000062</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462269</th>\n",
       "      <td>158834032</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0.062838</td>\n",
       "      <td>0.452039</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.484012</td>\n",
       "      <td>5.985858e-08</td>\n",
       "      <td>0.001049</td>\n",
       "      <td>1.383596e-08</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462270</th>\n",
       "      <td>158834132</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0.057111</td>\n",
       "      <td>0.398807</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.542938</td>\n",
       "      <td>5.218650e-08</td>\n",
       "      <td>0.001083</td>\n",
       "      <td>1.345144e-08</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>462270 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              idx  label_true     out_0     out_1     out_2     out_3  \\\n",
       "1       112448921       -1000  0.000060  0.004899  0.021637  0.111022   \n",
       "2       112449021       -1000  0.000049  0.003213  0.016925  0.061346   \n",
       "3       112449121       -1000  0.000057  0.003039  0.016792  0.044756   \n",
       "4       112449221       -1000  0.000115  0.003815  0.016265  0.042099   \n",
       "5       112449321       -1000  0.000194  0.004872  0.014967  0.050168   \n",
       "...           ...         ...       ...       ...       ...       ...   \n",
       "462266  158833732       -1000  0.076385  0.455255  0.000002  0.467187   \n",
       "462267  158833832       -1000  0.071031  0.464753  0.000002  0.463062   \n",
       "462268  158833932       -1000  0.067352  0.465470  0.000002  0.465978   \n",
       "462269  158834032       -1000  0.062838  0.452039  0.000002  0.484012   \n",
       "462270  158834132       -1000  0.057111  0.398807  0.000002  0.542938   \n",
       "\n",
       "               out_4     out_5         out_6     out_7  out_pred  \n",
       "1       2.193493e-03  0.860165  1.620770e-06  0.000022         5  \n",
       "2       2.321039e-03  0.916116  1.789388e-06  0.000028         5  \n",
       "3       2.357378e-03  0.932966  1.707474e-06  0.000031         5  \n",
       "4       1.511095e-03  0.936162  1.590745e-06  0.000032         5  \n",
       "5       1.806122e-03  0.927962  1.498758e-06  0.000029         5  \n",
       "...              ...       ...           ...       ...       ...  \n",
       "462266  6.948846e-08  0.001108  1.411081e-08  0.000063         3  \n",
       "462267  6.628539e-08  0.001092  1.382692e-08  0.000060         1  \n",
       "462268  6.614611e-08  0.001137  1.437202e-08  0.000062         3  \n",
       "462269  5.985858e-08  0.001049  1.383596e-08  0.000060         3  \n",
       "462270  5.218650e-08  0.001083  1.345144e-08  0.000059         3  \n",
       "\n",
       "[462270 rows x 11 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_new"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yangyixia",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
