{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code that might generate warnings\n",
    "# %%\n",
    "import warnings\n",
    "import datetime\n",
    "import os\n",
    "import math\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import progressbar\n",
    "import joblib\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "from multiprocessing import Process, Pool, Manager\n",
    "\n",
    "import itertools\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostClassifier\n",
    "from scipy.stats import skew, kurtosis\n",
    "from numpy.lib.stride_tricks import as_strided as stride\n",
    "from geopy.distance import geodesic\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "from math import sqrt\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from scipy.stats import mode\n",
    "from statsmodels.tools.tools import add_constant\n",
    "from statsmodels.stats.stattools import durbin_watson\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")  # Ignore all warnings\n",
    "\n",
    "# 每一条轨迹长短不一，在轨迹内采用滑动窗口L1（即决定窗口）,步长为L2,划分为子轨迹，提取子轨迹的特征。\n",
    "# 在子轨迹上训练模型，最后可以基于轨迹进行后处理\n",
    "L1 = 5  # s 滑动窗口的长度，暂时依据是20年直接给的5s的数据\n",
    "L2 = 1  # 滑动窗口的步长，假设1s内没有变化（主要原因是GPS数据是1s记录的）\n",
    "\n",
    "locs = ['Hand', 'Bag', 'Hips', 'Torso']\n",
    "\n",
    "loc = locs[0]  # 'Hand'\n",
    "dataset = 'train'\n",
    "\n",
    "label_map = {\n",
    "    1: 'Still',\n",
    "    2: 'Walking',\n",
    "    3: 'Run',\n",
    "    4: 'Bike',\n",
    "    5: 'Car',\n",
    "    6: 'Bus',\n",
    "    7: 'Train',\n",
    "    8: 'Subway'\n",
    "}\n",
    "\n",
    "filenames = {\n",
    "    'train': {\n",
    "        'Hand': {\n",
    "            'Location': '/DATA2/lvxiaoling/limengyuan/SHL2023/train/Hand/Location.pkl',\n",
    "            'Location_new': '/DATA2/lvxiaoling/limengyuan/SHL2023/train/Hand/Location_new.pkl',\n",
    "            # 进行标签匹配后的数据，时间戳是1HZ的label数据\n",
    "            'Mag': '/DATA2/lvxiaoling/limengyuan/SHL2023/train/Hand/Mag.pkl',\n",
    "            'Gyr': '/DATA2/lvxiaoling/limengyuan/SHL2023/train/Hand/Gyr.pkl',\n",
    "            'Acc': '/DATA2/lvxiaoling/limengyuan/SHL2023/train/Hand/Acc.pkl',\n",
    "            'GPS': '/DATA2/lvxiaoling/limengyuan/SHL2023/train/Hand/GPS.pkl',\n",
    "            'GPS_new': '/DATA2/lvxiaoling/limengyuan/SHL2023/train/Hand/GPS_new.pkl',\n",
    "        },\n",
    "        'Bag': {\n",
    "            'Location': '/DATA2/lvxiaoling/limengyuan/SHL2023/train/Bag/Location.pkl',\n",
    "            'Location_new': '/DATA2/lvxiaoling/limengyuan/SHL2023/train/Bag/Location_new.pkl',\n",
    "            'Mag': '/DATA2/lvxiaoling/limengyuan/SHL2023/train/Bag/Mag.pkl',\n",
    "            'Gyr': '/DATA2/lvxiaoling/limengyuan/SHL2023/train/Bag/Gyr.pkl',\n",
    "            'Acc': '/DATA2/lvxiaoling/limengyuan/SHL2023/train/Bag/Acc.pkl',\n",
    "            'GPS': '/DATA2/lvxiaoling/limengyuan/SHL2023/train/Bag/GPS.pkl',\n",
    "            'GPS_new': '/DATA2/lvxiaoling/limengyuan/SHL2023/train/Bag/GPS_new.pkl',\n",
    "        },\n",
    "        'Hips': {\n",
    "            'Location': '/DATA2/lvxiaoling/limengyuan/SHL2023/train/Hips/Location.pkl',\n",
    "            'Location_new': '/DATA2/lvxiaoling/limengyuan/SHL2023/train/Hips/Location_new.pkl',\n",
    "            'Mag': '/DATA2/lvxiaoling/limengyuan/SHL2023/train/Hips/Mag.pkl',\n",
    "            'Gyr': '/DATA2/lvxiaoling/limengyuan/SHL2023/train/Hips/Gyr.pkl',\n",
    "            'Acc': '/DATA2/lvxiaoling/limengyuan/SHL2023/train/Hips/Acc.pkl',\n",
    "            'GPS': '/DATA2/lvxiaoling/limengyuan/SHL2023/train/Hips/GPS.pkl',\n",
    "            'GPS_new': '/DATA2/lvxiaoling/limengyuan/SHL2023/train/Hips/GPS_new.pkl',\n",
    "        },\n",
    "        'Torso': {\n",
    "            'Location': '/DATA2/lvxiaoling/limengyuan/SHL2023/train/Torso/Location.pkl',\n",
    "            'Location_new': '/DATA2/lvxiaoling/limengyuan/SHL2023/train/Torso/Location_new.pkl',\n",
    "            'Mag': '/DATA2/lvxiaoling/limengyuan/SHL2023/train/Torso/Mag.pkl',\n",
    "            'Gyr': '/DATA2/lvxiaoling/limengyuan/SHL2023/train/Torso/Gyr.pkl',\n",
    "            'Acc': '/DATA2/lvxiaoling/limengyuan/SHL2023/train/Torso/Acc.pkl',\n",
    "            'GPS': '/DATA2/lvxiaoling/limengyuan/SHL2023/train/Torso/GPS.pkl',\n",
    "            'GPS_new': '/DATA2/lvxiaoling/limengyuan/SHL2023/train/Torso/GPS_new.pkl',\n",
    "        },\n",
    "        'Label': '/DATA2/lvxiaoling/limengyuan/SHL2023/train/Label.pkl'\n",
    "    },\n",
    "    'valid': {\n",
    "        'Hand': {\n",
    "            'Location': '/DATA2/lvxiaoling/limengyuan/SHL2023/valid/Hand/Location.pkl',\n",
    "            'Mag': '/DATA2/lvxiaoling/limengyuan/SHL2023/valid/Hand/Mag.pkl',\n",
    "            'Gyr': '/DATA2/lvxiaoling/limengyuan/SHL2023/valid/Hand/Gyr.pkl',\n",
    "            'Acc': '/DATA2/lvxiaoling/limengyuan/SHL2023/valid/Hand/Acc.pkl',\n",
    "            'GPS': '/DATA2/lvxiaoling/limengyuan/SHL2023/valid/Hand/GPS.pkl',\n",
    "        },\n",
    "        'Bag': {\n",
    "            'Location': '/DATA2/lvxiaoling/limengyuan/SHL2023/valid/Bag/Location.pkl',\n",
    "            'Location_new': '/DATA2/lvxiaoling/limengyuan/SHL2023/valid/Bag/Location_new.pkl',\n",
    "            'Mag': '/DATA2/lvxiaoling/limengyuan/SHL2023/valid/Bag/Mag.pkl',\n",
    "            'Gyr': '/DATA2/lvxiaoling/limengyuan/SHL2023/valid/Bag/Gyr.pkl',\n",
    "            'Acc': '/DATA2/lvxiaoling/limengyuan/SHL2023/valid/Bag/Acc.pkl',\n",
    "            'GPS': '/DATA2/lvxiaoling/limengyuan/SHL2023/valid/Bag/GPS.pkl',\n",
    "            'GPS_new': '/DATA2/lvxiaoling/limengyuan/SHL2023/valid/Bag/GPS_new.pkl',\n",
    "        },\n",
    "\n",
    "        'Hips': {\n",
    "            'Location': '/DATA2/lvxiaoling/limengyuan/SHL2023/valid/Hips/Location.pkl',\n",
    "            'Location_new': '/DATA2/lvxiaoling/limengyuan/SHL2023/valid/Hips/Location_new.pkl',\n",
    "            'Mag': '/DATA2/lvxiaoling/limengyuan/SHL2023/valid/Hips/Mag.pkl',\n",
    "            'Gyr': '/DATA2/lvxiaoling/limengyuan/SHL2023/valid/Hips/Gyr.pkl',\n",
    "            'Acc': '/DATA2/lvxiaoling/limengyuan/SHL2023/valid/Hips/Acc.pkl',\n",
    "            'GPS': '/DATA2/lvxiaoling/limengyuan/SHL2023/valid/Hips/GPS.pkl',\n",
    "            'GPS_new': '/DATA2/lvxiaoling/limengyuan/SHL2023/valid/Hips/GPS_new.pkl',\n",
    "        },\n",
    "        'Torso': {\n",
    "            'Location': '/DATA2/lvxiaoling/limengyuan/SHL2023/valid/Torso/Location.pkl',\n",
    "            'Location_new': '/DATA2/lvxiaoling/limengyuan/SHL2023/valid/Torso/Location_new.pkl',\n",
    "            'Mag': '/DATA2/lvxiaoling/limengyuan/SHL2023/valid/Torso/Mag.pkl',\n",
    "            'Gyr': '/DATA2/lvxiaoling/limengyuan/SHL2023/valid/Torso/Gyr.pkl',\n",
    "            'Acc': '/DATA2/lvxiaoling/limengyuan/SHL2023/valid/Torso/Acc.pkl',\n",
    "            'GPS': '/DATA2/lvxiaoling/limengyuan/SHL2023/valid/Torso/GPS.pkl',\n",
    "            'GPS_new': '/DATA2/lvxiaoling/limengyuan/SHL2023/valid/Torso/GPS_new.pkl',\n",
    "        },\n",
    "        'Label': '/DATA2/lvxiaoling/limengyuan/SHL2023/valid/Label.pkl',\n",
    "    },\n",
    "    'test': {\n",
    "        'Location': '/DATA2/lvxiaoling/limengyuan/SHL2023/test/Location.pkl',\n",
    "        'Location_new': '/DATA2/lvxiaoling/limengyuan/SHL2023/test/Location_new.pkl',\n",
    "        'Mag': '/DATA2/lvxiaoling/limengyuan/SHL2023/test/Mag.pkl',\n",
    "        'Gyr': '/DATA2/lvxiaoling/limengyuan/SHL2023/test/Gyr.pkl',\n",
    "        'Acc': '/DATA2/lvxiaoling/limengyuan/SHL2023/test/Acc.pkl',\n",
    "        'GPS': '/DATA2/lvxiaoling/limengyuan/SHL2023/test/GPS.pkl',\n",
    "        'GPS_new': '/DATA2/lvxiaoling/limengyuan/SHL2023/test/GPS_new.pkl',\n",
    "        'Label': '/DATA2/lvxiaoling/limengyuan/SHL2023/test/Label.pkl'\n",
    "    }\n",
    "}\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据读取\n",
    "\n",
    "假设前面的特征工程部分已经处理完成，接下来是完成模型部分\n",
    "前面已经得到了一个名为 results 的 DataFrame，现在需要进行 XGBoost 建模"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 读取数据\n",
    "results1 = pd.read_pickle('/DATA2/lvxiaoling/limengyuan/SHL2023/train/Hand/data.pkl').drop_duplicates(keep='first')\n",
    "results2 = pd.read_pickle('/DATA2/lvxiaoling/limengyuan/SHL2023/valid/Hand/data.pkl').drop_duplicates(keep='first')\n",
    "test = pd.read_pickle('/DATA2/lvxiaoling/limengyuan/SHL2023/test/data.pkl').drop_duplicates(keep='first')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def fill_NA(dataset):\n",
    "    # 计算每列的缺失值比例\n",
    "    missing_ratio = dataset.isnull().mean()\n",
    "    # 找到缺失值比例超过0.1的列\n",
    "    columns_to_drop = missing_ratio[missing_ratio > 0.1].index\n",
    "    # 删除缺失值比例超过0.1的列\n",
    "    dataset = dataset.drop(columns=columns_to_drop)\n",
    "    \n",
    "    # 将空值替换为0\n",
    "    new_dataset = dataset.fillna(0)\n",
    "    \n",
    "    # 在训练Boost模型时，要求标签类别必须是从0开始的连续整数\n",
    "    label_mapping = {1: 0, 2: 1, 3: 2, 4: 3, 5: 4, 6: 5, 7: 6, 8: 7}\n",
    "    new_dataset['label'] = new_dataset['label'].map(label_mapping)\n",
    "    #new_dataset = new_dataset.drop(columns=['idx', 'timestamp', 'trajectory_id'])\n",
    "    # 删的有点早难以匹配和后处理\n",
    "    return new_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 处理原始数据并将两个数据集进行拼接\n",
    "new_results1 = fill_NA(results1)\n",
    "new_results2 = fill_NA(results2)\n",
    "new_test = fill_NA(test)\n",
    "\n",
    "new_result = pd.concat([new_results1, new_results2,new_test], axis=0).reset_index(drop=True)\n",
    "#test一起处理哑变量\n",
    "\n",
    "# 处理哑变量\n",
    "dummy_columns = ['raliways_class',\n",
    "                 'transport_class',\n",
    "                 'traffic_class',\n",
    "                 'landuse_class',\n",
    "                 'roads_class',\n",
    "                 'roads_code',]\n",
    "# pd.get_dummies 是只能传入一列\n",
    "dummy_data = pd.concat([pd.get_dummies(new_result[dummy_columns_i]) for dummy_columns_i in dummy_columns], axis=1)\n",
    "# 拼接并保留原始分类变量\n",
    "new_result_with_dummies = pd.concat([new_result, dummy_data], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                524\n",
       "1                624\n",
       "2                724\n",
       "3                824\n",
       "4                924\n",
       "             ...    \n",
       "1581544    158833732\n",
       "1581545    158833832\n",
       "1581546    158833932\n",
       "1581547    158834032\n",
       "1581548    158834132\n",
       "Name: idx, Length: 1581549, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_result_with_dummies['idx']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集 X_train:(975986, 317)  y_train:(975986,)\n",
      "验证集 X_valid:(143293, 317)  y_valid:(143293,)\n"
     ]
    }
   ],
   "source": [
    "# 读取 train_idx, valid_idx 原来的idx应该重新运行代码被覆盖掉了\n",
    "train_idx = pd.read_pickle('/DATA2/lvxiaoling/limengyuan/SHL2023/train/trainidx.pkl')\n",
    "valid_idx = pd.read_pickle('/DATA2/lvxiaoling/limengyuan/SHL2023/train/validx.pkl')\n",
    "\n",
    "X = new_result_with_dummies\n",
    "\n",
    "data_train = X[X['idx'].isin(results1['idx'])]\n",
    "data_valid = X[X['idx'].isin(results2['idx'])]\n",
    "data_test = X[X['idx'].isin(test['idx'])]\n",
    "\n",
    "y_train = data_train['label'].values\n",
    "y_valid = data_valid['label'].values\n",
    "\n",
    "X_train = data_train.drop(columns=[ 'label', 'label_idx', 'idx', 'timestamp', 'trajectory_id']).values\n",
    "X_valid = data_valid.drop(columns=[ 'label', 'label_idx', 'idx', 'timestamp', 'trajectory_id']).values\n",
    "\n",
    "# 打印各个数据集的形状\n",
    "print(f\"训练集 X_train:{X_train.shape}  y_train:{y_train.shape}\")\n",
    "print(f\"验证集 X_valid:{X_valid.shape}  y_valid:{y_valid.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(975986, 322)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = data_test['label']\n",
    "X_test = data_test.drop(columns=['label', 'label_idx', 'idx', 'timestamp', 'trajectory_id']).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in dummy_columns:\n",
    "    if len(data_valid[~data_valid[i].isin(data_train[i])]):\n",
    "        print(i,'val')\n",
    "    if len(data_test[~data_test[i].isin(data_train[i])]):\n",
    "        print(i,'test')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # 合并训练集和验证集为训练集\n",
    "# X_train = pd.concat([X_train, X_val], axis=0)\n",
    "# y_train = pd.concat([y_train, y_val], axis=0)\n",
    "\n",
    "# 转化为 numpy\n",
    "if not isinstance(X_train, np.ndarray):\n",
    "    X_train, y_train = X_train.to_numpy(), y_train.to_numpy()\n",
    "if not isinstance(X_valid, np.ndarray):\n",
    "    X_valid, y_valid = X_valid.to_numpy(), y_valid.to_numpy()\n",
    "# X_test, y_test = X_test.to_numpy(), y_test.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_row_wise(x):\n",
    "    # 计算指数\n",
    "    exp_x = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
    "    # 计算每行的指数和\n",
    "    exp_sum = np.sum(exp_x, axis=1, keepdims=True)\n",
    "    # 计算Softmax结果\n",
    "    softmax_result = exp_x / exp_sum\n",
    "    return softmax_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_out(pred,y_probs,dataset):\n",
    "    if dataset == 'train':\n",
    "        res = data_train[['label', 'label_idx', 'idx', 'timestamp', 'trajectory_id']]\n",
    "    elif dataset == 'val':\n",
    "        res = data_valid[['label', 'label_idx', 'idx', 'timestamp', 'trajectory_id']]\n",
    "    elif dataset == 'test':\n",
    "        res = data_test[['label', 'label_idx', 'idx', 'timestamp', 'trajectory_id']]\n",
    "\n",
    "    res[['out_{}'.format(i) for i in range(8)]] =  y_probs\n",
    "    res['out_pred'] = pred\n",
    "    return res"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 建模\n",
    "\n",
    "分别建立XGBoost、LightGBM和catboost模型,但是由于机器学习的模型一般不需要使用验证集,所以将上面的训练集和验证集合并为训练集"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boost 模型"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 建立 XGBoost 模型\n",
    "\n",
    "建立 XGBoost 模型并进行预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "多线程\n",
    "\"\"\"\n",
    "num_classes = 8  # 8分类问题\n",
    "# 设置参数，包括线程数\n",
    "params = {\n",
    "    'objective': 'multi:softmax',\n",
    "    'num_class': num_classes,  # 类别数目\n",
    "    'nthread': 8,  # 设置线程数为8\n",
    "    # 其他参数...\n",
    "}\n",
    "\n",
    "# 创建DMatrix对象\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "\n",
    "# 训练模型\n",
    "xgboost_model = xgb.train(params, dtrain, num_boost_round=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存模型到本地\n",
    "xgboost_model.save_model('xgboost_model_Boost0622_raw.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8007509089767121\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.83      0.94      0.88     29676\n",
      "         1.0       0.91      0.84      0.87     25879\n",
      "         2.0       0.98      0.77      0.86      2754\n",
      "         3.0       0.94      0.21      0.34     12001\n",
      "         4.0       0.88      0.58      0.70     20438\n",
      "         5.0       0.34      0.84      0.48      9138\n",
      "         6.0       0.91      0.93      0.92     21763\n",
      "         7.0       0.91      0.96      0.94     21644\n",
      "\n",
      "    accuracy                           0.80    143293\n",
      "   macro avg       0.84      0.76      0.75    143293\n",
      "weighted avg       0.86      0.80      0.80    143293\n",
      "\n",
      "F1 score: 0.749640212886812\n"
     ]
    }
   ],
   "source": [
    "# # 加载模型，如果本地有保存模型的话\n",
    "# 验证集\n",
    "xgboost_model = xgb.Booster()\n",
    "xgboost_model.load_model('xgboost_model_Boost0622_raw.model')\n",
    "\n",
    "# 创建DMatrix对象\n",
    "dvalid = xgb.DMatrix(X_valid, label=y_valid)\n",
    "# 计算acc值\n",
    "y_pred_XGB = xgboost_model.predict(dvalid)\n",
    "y_probs_XGB = softmax_row_wise(xgboost_model.predict(dvalid,output_margin=True))\n",
    "# 整体的预测准确率\n",
    "accuracy_XGB = accuracy_score(y_valid, y_pred_XGB)\n",
    "print(\"Accuracy:\", accuracy_XGB)\n",
    "# 各个类别的预测准确率\n",
    "report_XGB = classification_report(y_valid, y_pred_XGB)\n",
    "print(report_XGB)\n",
    "# 计算宏F1值\n",
    "f1_XGB = f1_score(y_valid, y_pred_XGB, average='macro')\n",
    "print(\"F1 score:\", f1_XGB)\n",
    "xg_valid = get_out(pred=y_pred_XGB,y_probs= y_probs_XGB,dataset='val')\n",
    "xg_valid.to_pickle('/DATA2/lvxiaoling/limengyuan/SHL2023/out_put2/val_ml1.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7860838"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_probs_XGB.max(1).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.9332351 ,  1.2616082 , -1.0502172 , -0.42409664, -0.66000843,\n",
       "        0.4752401 , -0.5853704 , -0.233704  ], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.942334213810444\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.96      0.94    121421\n",
      "         1.0       0.97      0.96      0.96    121730\n",
      "         2.0       0.99      0.98      0.99     42051\n",
      "         3.0       0.99      0.97      0.98    116713\n",
      "         4.0       0.92      0.90      0.91    158280\n",
      "         5.0       0.88      0.89      0.89    141178\n",
      "         6.0       0.94      0.98      0.96    155870\n",
      "         7.0       0.96      0.93      0.95    118743\n",
      "\n",
      "    accuracy                           0.94    975986\n",
      "   macro avg       0.95      0.95      0.95    975986\n",
      "weighted avg       0.94      0.94      0.94    975986\n",
      "\n",
      "F1 score: 0.9478051324856609\n"
     ]
    }
   ],
   "source": [
    "# 训练集\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "# 计算acc值\n",
    "y_pred_XGB = xgboost_model.predict(dtrain)\n",
    "y_probs_XGB = softmax_row_wise(xgboost_model.predict(dtrain,output_margin=True))\n",
    "# 整体的预测准确率\n",
    "accuracy_XGB = accuracy_score(y_train, y_pred_XGB)\n",
    "print(\"Accuracy:\", accuracy_XGB)\n",
    "# 各个类别的预测准确率\n",
    "report_XGB = classification_report(y_train, y_pred_XGB)\n",
    "print(report_XGB)\n",
    "# 计算宏F1值\n",
    "f1_XGB = f1_score(y_train, y_pred_XGB, average='macro')\n",
    "print(\"F1 score:\", f1_XGB)\n",
    "\n",
    "xg_train = get_out(pred=y_pred_XGB,y_probs= y_probs_XGB,dataset='train')\n",
    "#xg_train.to_pickle('/DATA2/lvxiaoling/limengyuan/SHL2023/out_put/train_ml1.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试集\n",
    "dtest = xgb.DMatrix(X_test, label=y_test.fillna(0))\n",
    "# 计算acc值\n",
    "y_pred_XGB = xgboost_model.predict(dtest)\n",
    "y_probs_XGB = softmax_row_wise(xgboost_model.predict(dtest,output_margin=True))\n",
    "\n",
    "\n",
    "xg_test = get_out(pred=y_pred_XGB,y_probs= y_probs_XGB,dataset='test')\n",
    "# xg_test.to_pickle('/DATA2/lvxiaoling/limengyuan/SHL2023/out_put/test_ml1.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 建立 LightGBM 模型\n",
    "\n",
    "建立 LightGBM 模型并进行预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义模型参数\n",
    "num_classes = 8  # 8分类问题\n",
    "\n",
    "params = {\n",
    "    'objective': 'multiclass',  # 多类别分类问题\n",
    "    'num_class': num_classes,  # 类别数量\n",
    "    'metric': 'multi_logloss'  # 损失函数\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMClassifier(metric=&#x27;multi_logloss&#x27;, num_class=8, objective=&#x27;multiclass&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(metric=&#x27;multi_logloss&#x27;, num_class=8, objective=&#x27;multiclass&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LGBMClassifier(metric='multi_logloss', num_class=8, objective='multiclass')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 建立 LightGBM 模型\n",
    "lgb_model = lgb.LGBMClassifier(**params)\n",
    "lgb_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lgb_model_Boost0622_raw.pkl']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 保存模型到文件\n",
    "joblib.dump(lgb_model, 'lgb_model_Boost0622_raw.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8080087652572003\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      0.94      0.91     29676\n",
      "         1.0       0.88      0.87      0.87     25879\n",
      "         2.0       0.94      0.76      0.84      2754\n",
      "         3.0       0.97      0.24      0.39     12001\n",
      "         4.0       0.80      0.54      0.64     20438\n",
      "         5.0       0.38      0.86      0.52      9138\n",
      "         6.0       0.91      0.93      0.92     21763\n",
      "         7.0       0.90      0.98      0.94     21644\n",
      "\n",
      "    accuracy                           0.81    143293\n",
      "   macro avg       0.83      0.77      0.75    143293\n",
      "weighted avg       0.85      0.81      0.80    143293\n",
      "\n",
      "F1 score: 0.7544718019250383\n"
     ]
    }
   ],
   "source": [
    "# # 加载保存的模型\n",
    "# 验证集\n",
    "lgb_model = joblib.load('lgb_model_Boost0622_raw.pkl')\n",
    "\n",
    "# 计算acc值\n",
    "y_pred_LGBM = lgb_model.predict(X_valid)\n",
    "y_probs_LGBM = lgb_model.predict_proba(X_valid)\n",
    "# 整体的预测准确率\n",
    "accuracy_LGBM = accuracy_score(y_valid, y_pred_LGBM)\n",
    "print(\"Accuracy:\", accuracy_LGBM)\n",
    "# 各个类别的预测准确率\n",
    "report_LGBM = classification_report(y_valid, y_pred_LGBM)\n",
    "print(report_LGBM)\n",
    "# 计算宏F1值\n",
    "f1_LGBM = f1_score(y_valid, y_pred_LGBM, average='macro')\n",
    "print(\"F1 score:\", f1_LGBM)\n",
    "lgbm_val = get_out(pred=y_pred_LGBM,y_probs= y_probs_LGBM,dataset='val')\n",
    "lgbm_val.to_pickle('/DATA2/lvxiaoling/limengyuan/SHL2023/out_put2/val_ml2.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9920892271481407\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.98      0.99    120675\n",
      "         1.0       1.00      1.00      1.00    117175\n",
      "         2.0       0.97      1.00      0.99     35805\n",
      "         3.0       1.00      1.00      1.00    110674\n",
      "         4.0       0.99      0.99      0.99    146300\n",
      "         5.0       0.99      0.99      0.99    121841\n",
      "         6.0       0.99      1.00      0.99    147554\n",
      "         7.0       0.99      0.99      0.99    116827\n",
      "\n",
      "    accuracy                           0.99    916851\n",
      "   macro avg       0.99      0.99      0.99    916851\n",
      "weighted avg       0.99      0.99      0.99    916851\n",
      "\n",
      "F1 score: 0.9915254422190407\n"
     ]
    }
   ],
   "source": [
    "# 训练集\n",
    "y_pred_LGBM = lgb_model.predict(X_train)\n",
    "y_probs_LGBM = lgb_model.predict_proba(X_train)\n",
    "\n",
    "# 整体的预测准确率\n",
    "accuracy_LGBM = accuracy_score(y_train, y_pred_LGBM)\n",
    "print(\"Accuracy:\", accuracy_LGBM)\n",
    "# 各个类别的预测准确率\n",
    "report_LGBM = classification_report(y_train, y_pred_LGBM)\n",
    "print(report_LGBM)\n",
    "# 计算宏F1值\n",
    "f1_LGBM = f1_score(y_train, y_pred_LGBM, average='macro')\n",
    "print(\"F1 score:\", f1_LGBM)\n",
    "lgbm_train = get_out(pred=y_pred_LGBM,y_probs= y_probs_LGBM,dataset='train')\n",
    "# lgbm_train.to_pickle('/DATA2/lvxiaoling/limengyuan/SHL2023/out_put/train_ml2.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试集\n",
    "y_pred_LGBM = lgb_model.predict(X_test)\n",
    "y_probs_LGBM = lgb_model.predict_proba(X_test)\n",
    "\n",
    "\n",
    "\n",
    "lgbm_test = get_out(pred=y_pred_LGBM,y_probs= y_probs_LGBM,dataset='test')\n",
    "# lgbm_test.to_pickle('/DATA2/lvxiaoling/limengyuan/SHL2023/out_put/test_ml2.pkl')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 建立 CatBoost 模型\n",
    "\n",
    "建立 CatBoost 模型并进行预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x7f981447c4c0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 建立 CatBoost 模型\n",
    "cat_model = CatBoostClassifier(iterations=100, learning_rate=0.1, depth=6, thread_count=8)\n",
    "# 拟合模型\n",
    "cat_model.fit(X_train, y_train, verbose=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存模型到本地文件\n",
    "cat_model.save_model(\"catboost_model_Boost0622_raw.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7969963640931518\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.84      0.93      0.88     29676\n",
      "         1.0       0.92      0.82      0.87     25879\n",
      "         2.0       0.99      0.80      0.88      2754\n",
      "         3.0       0.78      0.09      0.15     12001\n",
      "         4.0       0.87      0.62      0.72     20438\n",
      "         5.0       0.33      0.87      0.47      9138\n",
      "         6.0       0.92      0.95      0.94     21763\n",
      "         7.0       0.92      0.97      0.94     21644\n",
      "\n",
      "    accuracy                           0.80    143293\n",
      "   macro avg       0.82      0.75      0.73    143293\n",
      "weighted avg       0.85      0.80      0.79    143293\n",
      "\n",
      "F1 score: 0.7332095851321211\n"
     ]
    }
   ],
   "source": [
    "# # 加载保存的CatBoost模型\n",
    "# 验证集\n",
    "cat_model = CatBoostClassifier()\n",
    "cat_model.load_model(\"catboost_model_Boost0622_raw.bin\")\n",
    "\n",
    "# 计算acc值\n",
    "y_pred_cat = cat_model.predict(X_valid)\n",
    "y_probs_cat  = cat_model.predict_proba(X_valid)\n",
    "# 整体的预测准确率\n",
    "accuracy_cat = accuracy_score(y_valid, y_pred_cat)\n",
    "print(\"Accuracy:\", accuracy_cat)\n",
    "# 各个类别的预测准确率\n",
    "report_cat = classification_report(y_valid, y_pred_cat)\n",
    "print(report_cat)\n",
    "# 计算宏F1值\n",
    "f1_cat = f1_score(y_valid, y_pred_cat, average='macro')\n",
    "print(\"F1 score:\", f1_cat)\n",
    "\n",
    "\n",
    "cat_val = get_out(pred=y_pred_cat,y_probs= y_probs_cat,dataset='val')\n",
    "cat_val.to_pickle('/DATA2/lvxiaoling/limengyuan/SHL2023/out_put2/val_ml3.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9408060851763264\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.95      0.94    120675\n",
      "         1.0       0.94      0.94      0.94    117175\n",
      "         2.0       0.98      0.96      0.97     35805\n",
      "         3.0       0.98      0.97      0.97    110674\n",
      "         4.0       0.94      0.92      0.93    146300\n",
      "         5.0       0.91      0.90      0.90    121841\n",
      "         6.0       0.94      0.97      0.96    147554\n",
      "         7.0       0.95      0.92      0.94    116827\n",
      "\n",
      "    accuracy                           0.94    916851\n",
      "   macro avg       0.95      0.94      0.94    916851\n",
      "weighted avg       0.94      0.94      0.94    916851\n",
      "\n",
      "F1 score: 0.9437674909457809\n"
     ]
    }
   ],
   "source": [
    "# 计算acc值\n",
    "y_pred_cat = cat_model.predict(X_train)\n",
    "y_probs_cat  = cat_model.predict_proba(X_train)\n",
    "\n",
    "# 整体的预测准确率\n",
    "accuracy_cat = accuracy_score(y_train, y_pred_cat)\n",
    "print(\"Accuracy:\", accuracy_cat)\n",
    "# 各个类别的预测准确率\n",
    "report_cat = classification_report(y_train, y_pred_cat)\n",
    "print(report_cat)\n",
    "# 计算宏F1值\n",
    "f1_cat = f1_score(y_train, y_pred_cat, average='macro')\n",
    "print(\"F1 score:\", f1_cat)\n",
    "\n",
    "cat_train = get_out(pred=y_pred_cat,y_probs= y_probs_cat,dataset='train')\n",
    "cat_train.to_pickle('/DATA2/lvxiaoling/limengyuan/SHL2023/out_put/train_ml3.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算acc值\n",
    "y_pred_cat = cat_model.predict(X_test)\n",
    "y_probs_cat  = cat_model.predict_proba(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "cat_test = get_out(pred=y_pred_cat,y_probs= y_probs_cat,dataset='test')\n",
    "cat_test.to_pickle('/DATA2/lvxiaoling/limengyuan/SHL2023/out_put/test_ml3.pkl')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "综上，最后进入stacking的模型将会是CatBoost模型。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 建立集成模型\n",
    "\n",
    "用 XGBoost、LightGBM、CatBoost 三个模型进行集成学习"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 首先导入上面已经训练好保存至本地的 model\n",
    "# xgboost_model = xgb.XGBClassifier()\n",
    "# xgboost_model.load_model('xgboost_model.model')\n",
    "\n",
    "# lgb_model = joblib.load('lgb_model.pkl')\n",
    "\n",
    "# cat_model = CatBoostClassifier()\n",
    "# cat_model.load_model(\"catboost_model.bin\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(202428, 3)\n"
     ]
    }
   ],
   "source": [
    "# 将每个基模型的预测结果收集起来，形成一个预测结果的集合\n",
    "# y_pred_LGBM = lgb_model.predict(X_test)\n",
    "# y_pred_cat = cat_model.predict(X_test)\n",
    "# y_pred_XGB = xgboost_model.predict(X_test)\n",
    "\n",
    "y_pred_ensemble = np.column_stack((y_pred_XGB, y_pred_LGBM, y_pred_cat))\n",
    "print(y_pred_ensemble.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(202428,)\n"
     ]
    }
   ],
   "source": [
    "# 进行投票得出最后的预测结果\n",
    "modes, counts = mode(y_pred_ensemble, axis=1)\n",
    "y_pred = modes[:, 0]\n",
    "print(y_pred.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# 整体的预测准确率\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m accuracy \u001b[39m=\u001b[39m accuracy_score(y_test, y_pred)\n\u001b[1;32m      3\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mAccuracy:\u001b[39m\u001b[39m\"\u001b[39m, accuracy)\n\u001b[1;32m      4\u001b[0m \u001b[39m# 各个类别的预测准确率\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'y_test' is not defined"
     ]
    }
   ],
   "source": [
    "# 整体的预测准确率\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "# 各个类别的预测准确率\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(report)\n",
    "# 计算宏F1值\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "print(\"F1 score:\", f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yangyixia",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
