{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0ee5d1d-c478-4b63-9df5-f77906c6256b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lmy/7_model_gps_road.py\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.functional as f\n",
    "from torch.nn import Parameter\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import torch.optim as optim\n",
    "from torch.nn.utils.rnn import pad_sequence \n",
    "import itertools\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "from prettytable import PrettyTable\n",
    "import datetime\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import time\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")  # Ignore all warnings\n",
    "import math\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import progressbar\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "from scipy.stats import skew, kurtosis\n",
    "from numpy.lib.stride_tricks import as_strided as stride\n",
    "from geopy.distance import geodesic\n",
    "import _pickle as cPickle\n",
    "import argparse\n",
    "import random\n",
    "from utils import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "print('lmy/7_model_gps_road.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9c116d3-fda5-4dca-badc-38565499a29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames =get_filenames()\n",
    "\n",
    "# %%\n",
    "args = get_parser()\n",
    "args.transformer = 1\n",
    "args.gpu = 0\n",
    "args.STAT_NET_input_road = np.array([ 8, 11, 20, 21, 27,  6])#train_data.stat_data.loc[:,get_road_name()].max().values+1#最大值加1\n",
    "\n",
    "args.device = 'cuda:{}'.format(args.gpu) if (args.gpu>=0) & torch.cuda.is_available() else 'cpu'\n",
    "#args.now = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S:%f==') #时间\n",
    "args.model_save = '/DATA2/lvxiaoling/limengyuan/SHL2023/save/models2023-06-19 23_59_29_759129==.pth'\n",
    "\n",
    "args.CONV_SENSORS_input_dim = 12\n",
    "args.CONV_GEO_num_feat = 6\n",
    "args.STAT_NET_input_sensors = 195\n",
    "args.STAT_NET_input_geo = 26\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b7d49d8-5d31-4e21-a6f6-efb2ab9323a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class  dset(Dataset):\n",
    "    def __init__(self, data_sensor,data_gps,stat_data):\n",
    "        super(dset, self).__init__()\n",
    "        self.data_sensor = data_sensor\n",
    "        self.data_gps = data_gps\n",
    "        self.stat_data = stat_data\n",
    "        self.name_dict = {name:i for i,name in enumerate(stat_data)}\n",
    "        self.stat_sensors = [self.name_dict[i] for i in get_sensors_name()]\n",
    "        self.stat_gps = [self.name_dict[i] for i in get_gps_name()]\n",
    "        self.stat_road = [self.name_dict[i] for i in get_road_name()]\n",
    "    def __len__(self):\n",
    "        return len(self.data_gps)\n",
    "    def  __getitem__(self, i):\n",
    "        stat_value = self.stat_data[self.stat_data['idx'].isin(self.data_gps[i][args.L1-1:,-3])].values\n",
    "        if len(stat_value)!= len(self.data_gps[i][args.L1-1:,-3]):\n",
    "            print(i)\n",
    "        return torch.tensor(self.data_sensor[i]),torch.tensor(self.data_gps[i]),torch.tensor(stat_value[:,self.stat_sensors]),torch.tensor(stat_value[:,self.stat_gps]),torch.tensor(stat_value[:,self.stat_road]).long()\n",
    "    #返回的10分钟内的数据\n",
    "    #data_sensor,data_gps,label,idx\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 加载数据\n",
    "\n",
    "# %%\n",
    "def collate_batch(batch):\n",
    "    data_sensor_list,data_gps_list,lengths,stat_list1,stat_list2,stat_list3 =  [], [],[],[], [],[]\n",
    "    batch.sort(key=lambda x: len(x[0]), reverse=True)#按照长度的大小进行排序\n",
    "    for (data_sensor_,data_gps_,stat_list1_i,stat_list2_i,stat_list3_i) in batch:\n",
    "\n",
    "\n",
    "\n",
    "        data_sensor_list.append(data_sensor_)\n",
    "        data_gps_list.append(data_gps_)\n",
    "        \n",
    "        lengths.append(data_gps_.shape[0])\n",
    "        stat_list1.append(stat_list1_i)\n",
    "        stat_list2.append(stat_list2_i)\n",
    "        stat_list3.append(stat_list3_i)\n",
    "\n",
    "    data_sensor_list = pad_sequence(data_sensor_list, padding_value=args.pad_value, batch_first=True)#进行填充，每个batch中的句子需要有相同的长度\n",
    "    data_gps_list = pad_sequence(data_gps_list, padding_value=args.pad_value, batch_first=True)#进行填充，每个batch中的句子需要有相同的长度\n",
    "    \n",
    "    stat_list1 = pad_sequence(stat_list1, padding_value=args.pad_value, batch_first=True)#进行填充，每个batch中的句子需要有相同的长度\n",
    "    stat_list2 = pad_sequence(stat_list2, padding_value=args.pad_value, batch_first=True)#进行填充，每个batch中的句子需要有相同的长度\n",
    "    stat_list3 = pad_sequence(stat_list3, padding_value=args.pad_value, batch_first=True)#进行填充，每个batch中的句子需要有相同的长度\n",
    "    roads = []\n",
    "    for i in range(6):\n",
    "        road_i = stat_list3[:,:,[i]]\n",
    "        road_i[road_i==args.pad_value] = args.STAT_NET_input_road[i]\n",
    "        roads.append(road_i)\n",
    "    stat_list3 = torch.cat(roads,dim=-1)\n",
    "\n",
    "        #stat_list3[:,:,i][stat_list3[:,:,i]==args.pad_value] = args.STAT_NET_input_road[i]\n",
    "\n",
    "    label =  torch.tensor(data_gps_list)[:,:,-4].long()\n",
    "    label[label>0] = label[label>0]-1\n",
    "    #data_sensor,data_gps,stat_sensors,stat_gps,stat_road, label,idx,trip_idx, lengths in train_dataloader\n",
    "    return data_sensor_list.float(),data_gps_list[:,:,:-4].float(),\\\n",
    "        stat_list1.float(),stat_list2.float(),stat_list3.long(),\\\n",
    "        label,torch.tensor(data_gps_list)[:,:,-3].long(),torch.tensor(data_gps_list)[:,:,-2].long(), lengths\n",
    "        #'label','idx','trajectory_id','label_idx'\\\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52ea8987-20e2-475d-9937-c65b9b2929c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/DATA2/lvxiaoling/limengyuan/SHL2023/save/models2023-06-19 23_59_29_759129==.pth\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# %%\n",
    "class CONV_SENSORS(nn.Module):\n",
    "    def __init__(self,input_dim=3, num_filter = 64,kernel_size = 500, stride=100):\n",
    "        super(CONV_SENSORS,self).__init__()\n",
    "        self.conv = nn.Conv1d(input_dim, num_filter, kernel_size, stride = stride)\n",
    "\n",
    "    def forward(self,data_sensor):# traj:batch_size*seq_len*17\n",
    "        # 地理卷积\n",
    "        data_sensor = data_sensor.permute(0,2,1)#batch_size,seq_len,num\n",
    "        data_sensor = F.elu(self.conv(data_sensor)).permute(0,2,1)# L*seq_len'*num_filter\n",
    "        return data_sensor\n",
    "\n",
    "\n",
    "# %%\n",
    "class CONV_GEO(nn.Module):\n",
    "    def __init__(self,kernel_size=5,num_filter=64,num_feat = 6):\n",
    "        super(CONV_GEO,self).__init__()\n",
    "        self.process_coords = nn.Linear(2,16)\n",
    "        self.conv1 = nn.Conv1d(16,num_filter,kernel_size)\n",
    "        self.conv2 = nn.Conv1d(num_feat,num_filter,kernel_size)\n",
    "\n",
    "    def forward(self,data_gps):# traj:batch_size*seq_len*17\n",
    "        # 地理卷积\n",
    "        \n",
    "        lngs_lats = data_gps[:,:,:2] #batch_size*seq_len*2\n",
    "        locs1 = torch.tanh(self.process_coords(lngs_lats))# batch_size*seq_len*16\n",
    "        locs1 =locs1.permute(0,2,1)# batch_size*16*seq_len\n",
    "        conv_locs1 = F.elu(self.conv1(locs1)).permute(0,2,1)# L*seq_len'*num_filter\n",
    "        \n",
    "        # 特征卷积\n",
    "        features = data_gps[:,:,2:]# batch_size*seq_len*14\n",
    "        locs2 = features.permute(0,2,1)# batch_size*14*seq_len\n",
    "        conv_locs2 = F.elu(self.conv2(locs2)).permute(0,2,1)# L*seq_len'*num_filter\n",
    "        \n",
    "        return torch.concat([conv_locs1,conv_locs2],dim=2)#地理、特征、时间\n",
    "        ## L*seq_len'*num_filter\n",
    "\n",
    "# %%\n",
    "class STAT_NET(nn.Module):\n",
    "    def __init__(self,args=args,\n",
    "                 input_road = [3,4,5,6,7,8],road_embedding =16, \n",
    "                 input_sensors=125,sensors_embedding = 64,\n",
    "                 input_geo=125,geo_embedding = 64):\n",
    "        super(STAT_NET, self).__init__()\n",
    "        self.pad_value = args.pad_value\n",
    "        self.args = args\n",
    "        self.input_road = input_road\n",
    "        self.emb = nn.ModuleList([nn.Embedding(i+1,road_embedding,padding_idx=i)    for  i in input_road])\n",
    "        self.fc_sensors = nn.Linear(input_sensors,sensors_embedding)\n",
    "        self.fc_geo = nn.Linear(input_geo,geo_embedding)\n",
    "        #embedding层\n",
    "        \n",
    "\n",
    "    def forward(self, stat_sensors,stat_gps,stat_road):\n",
    "        stat_sensors = self.fc_sensors(stat_sensors)\n",
    "        stat_gps = self.fc_geo(stat_gps)\n",
    "\n",
    "        roads = []\n",
    "        for i,layer in enumerate(self.emb):\n",
    "            road_i = stat_road[:,:,i]#batch_size,sqe_len,feat_num\n",
    "            #road_i[road_i==args.pad_value] = self.input_road[i]\n",
    "            road_i = layer(road_i)\n",
    "            roads.append(road_i)\n",
    "        roads = torch.cat(roads,dim=-1)\n",
    "        return roads\n",
    "\n",
    "# %%\n",
    "class BILSTM(torch.nn.Module):\n",
    "    def __init__(self,args=args,input_dim=64+128, d_model = 128,out_dim=8):\n",
    "        super(BILSTM, self).__init__()\n",
    "        self.pad_value = args.pad_value\n",
    "        self.args = args\n",
    "        #embedding层\n",
    "        self.lstm = nn.LSTM(input_dim,d_model//2, num_layers = args.lstm_layer, bidirectional = True,\n",
    "                                dropout=args.dropout, batch_first=True)\n",
    "        self.projection = nn.Linear(d_model, out_dim)\n",
    "\n",
    "    def forward(self, x, lengths):\n",
    "        lengths = torch.tensor(lengths)-(self.args.L1-1)\n",
    "        packed_embedded = nn.utils.rnn.pack_padded_sequence(x, lengths, batch_first=True)        \n",
    "        packed_output, (hidden, cell) = self.lstm(packed_embedded)#lstm层\n",
    "        # hidden = [n layers *2, batch size, hidden dim]最后一个step的hidden\n",
    "        # cell = [n layers * 2, batch size, hidden dim]最终一个step的cell\n",
    "        x, output_lengths = nn.utils.rnn.pad_packed_sequence(packed_output, batch_first=True)\n",
    "        x = self.projection(x)\n",
    "        return x\n",
    "if args.transformer:\n",
    "    class BILSTM(torch.nn.Module):\n",
    "        def __init__(self,args=args,input_dim=64+128, d_model = 128,out_dim=8):\n",
    "            super(BILSTM, self).__init__()\n",
    "            self.pad_value = args.pad_value\n",
    "            self.args = args\n",
    "            #embedding层\n",
    "            self.lstm = nn.LSTM(input_dim,d_model//2, num_layers = args.lstm_layer, bidirectional = True,\n",
    "                                    dropout=args.dropout, batch_first=True)\n",
    "            self.encoder_layer = nn.TransformerEncoderLayer(d_model * args.nheads, args.nheads, args.ff_size, args.dropout, batch_first=True)\n",
    "            self.encoder = nn.TransformerEncoder(self.encoder_layer, args.n_layers)\n",
    "            self.fc = nn.Linear(d_model * args.nheads, d_model)\n",
    "\n",
    "            self.projection = nn.Linear(d_model, out_dim)\n",
    "\n",
    "        def forward(self, x, lengths):\n",
    "            lengths = torch.tensor(lengths)-(self.args.L1-1)\n",
    "            packed_embedded = nn.utils.rnn.pack_padded_sequence(x, lengths, batch_first=True)        \n",
    "            packed_output, (hidden, cell) = self.lstm(packed_embedded)#lstm层\n",
    "            # hidden = [n layers *2, batch size, hidden dim]最后一个step的hidden\n",
    "            # cell = [n layers * 2, batch size, hidden dim]最终一个step的cell\n",
    "            x, output_lengths = nn.utils.rnn.pad_packed_sequence(packed_output, batch_first=True)\n",
    "            mask = self.get_mask(lengths,x.shape[0])\n",
    "            x = self.encoder(x.repeat(1, 1, self.args.nheads), src_key_padding_mask=mask)\n",
    "            x = self.fc(x)\n",
    "            x = self.projection(x)\n",
    "\n",
    "\n",
    "            return x\n",
    "        def get_mask(self,sentence_lengths,batch_len):\n",
    "            # 计算最大句子长度\n",
    "            max_length = max(sentence_lengths)\n",
    "\n",
    "            # 创建一个零填充的张量，大小为(batch_size, max_length)\n",
    "            src_key_padding_mask = torch.zeros((batch_len, max_length), dtype=torch.bool)\n",
    "\n",
    "            # 对每个句子进行遍历，根据句子长度进行填充\n",
    "            for i, length in enumerate(sentence_lengths):\n",
    "                src_key_padding_mask[i, :length] = 1\n",
    "\n",
    "# %%\n",
    "if False:\n",
    "    data_sensor,data_gps,stat_sensors,stat_gps,stat_road, label,idx,trip_idx, length = next(iter(train_loader))\n",
    "\n",
    "    m1 = CONV_SENSORS(input_dim=args.CONV_SENSORS_input_dim, num_filter =args.num_filter)\n",
    "    r1 = m1(data_sensor)\n",
    "    m2 = CONV_GEO(num_feat = args.CONV_GEO_num_feat,num_filter =args.num_filter)\n",
    "    r2 = m2(data_gps)\n",
    "    m3 = STAT_NET(  input_road = args.STAT_NET_input_road,road_embedding =args.STAT_NET_road_embedding, \n",
    "                    input_sensors=args.STAT_NET_input_sensors,sensors_embedding = args.STAT_NET_sensors_embedding,\n",
    "                    input_geo=args.STAT_NET_input_geo,geo_embedding = args.STAT_NET_geo_embedding)\n",
    "    r3 = m3(stat_sensors,stat_gps,stat_road)\n",
    "    r = torch.cat([r1,r2,r3],dim=-1)\n",
    "\n",
    "    m3 = BILSTM(input_dim=3*args.num_filter +args.STAT_NET_geo_embedding+len( args.STAT_NET_input_road)*args.STAT_NET_road_embedding,args=args)\n",
    "    r4 = m3(r,length)\n",
    "\n",
    "\n",
    "def evaluate(model_s,model_g,model_stat,model,loss_fn,train_dataloader):\n",
    "    model_s.eval()\n",
    "    model_g.eval()\n",
    "    model_stat.eval()\n",
    "    model.eval()\n",
    "\n",
    "    \n",
    "    losses = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data_sensor,data_gps,stat_sensors,stat_gps,stat_road, label,idx,trip_idx, lengths in train_dataloader:\n",
    "            data_sensor = data_sensor.to(args.device)\n",
    "            data_gps = data_gps.to(args.device)\n",
    "            stat_sensors,stat_gps,stat_road = stat_sensors.to(args.device),stat_gps.to(args.device),stat_road.to(args.device)\n",
    "            label = label.to(args.device)[:,(args.L1-1):]\n",
    "\n",
    "            output_s = model_s(data_sensor)\n",
    "            output_g = model_g(data_gps)\n",
    "            output_stat = model_stat(stat_sensors,stat_gps,stat_road)\n",
    "            out = model(torch.cat([output_s,output_g,output_stat],dim=-1),lengths)\n",
    "\n",
    "            \n",
    "            loss = loss_fn( out.reshape(-1, out.shape[-1]), label.reshape(-1))\n",
    "           \n",
    "            losses += loss.item() \n",
    "            \n",
    "            mask = label ==args.pad_value\n",
    "            pred = torch.argmax(out, dim=2)\n",
    "            correct +=  (pred ==label ).masked_fill(mask,0).sum().item() / (~mask).sum()\n",
    "            \n",
    "    model_s.train()\n",
    "    model_g.train()\n",
    "    model_stat.train()\n",
    "    model.train()\n",
    "    return losses / len(train_dataloader),correct/len(train_dataloader)\n",
    "\n",
    "# %%\n",
    "def weight_init(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        \n",
    "        nn.init.xavier_normal_(m.weight)\n",
    "        nn.init.constant_(m.bias, 0)\n",
    "    # 也可以判断是否为conv2d，使用相应的初始化方式 \n",
    "    elif isinstance(m, nn.Conv2d):\n",
    "        nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "     # 是否为批归一化层\n",
    "    elif isinstance(m, nn.BatchNorm2d):\n",
    "        nn.init.constant_(m.weight, 1)\n",
    "        nn.init.constant_(m.bias, 0)\n",
    "\n",
    "# %%\n",
    "\n",
    "\n",
    "# %%\n",
    "model_s = CONV_SENSORS(input_dim=args.CONV_SENSORS_input_dim, num_filter =args.num_filter).to(args.device).apply(weight_init)\n",
    "model_g = CONV_GEO(num_feat = args.CONV_GEO_num_feat,num_filter =args.num_filter).to(args.device).apply(weight_init)\n",
    "model_stat = STAT_NET(input_road = args.STAT_NET_input_road,road_embedding =args.STAT_NET_road_embedding, \n",
    "                 input_sensors=args.STAT_NET_input_sensors,sensors_embedding = args.STAT_NET_sensors_embedding,\n",
    "                 input_geo=args.STAT_NET_input_geo,geo_embedding = args.STAT_NET_geo_embedding).to(args.device).apply(weight_init)\n",
    "model = BILSTM(input_dim=3*args.num_filter+len( args.STAT_NET_input_road)*args.STAT_NET_road_embedding,args=args).to(args.device).apply(weight_init)\n",
    "\n",
    "\n",
    "if args.weightloss:\n",
    "    weight = torch.tensor([1.0048, 1.0022, 2.9012, 1.0453, 0.7708, 0.8641, 0.7827, 1.0274]).to(args.device)\n",
    "    criterion  = nn.CrossEntropyLoss(ignore_index=args.pad_value,weight=weight)\n",
    "else:\n",
    "    criterion  = nn.CrossEntropyLoss(ignore_index=args.pad_value)\n",
    "\n",
    "\n",
    "#args.model_save = '/DATA1/EvolveGCN/limengyuan/datas/models/models2023-06-16 09:35:17:728874==.pth'\n",
    "checkpoint = torch.load( args.model_save)\n",
    "model_s.load_state_dict(checkpoint['model_s'])\n",
    "model_g.load_state_dict(checkpoint['model_g'])\n",
    "model_stat.load_state_dict(checkpoint['model_stat'])\n",
    "model.load_state_dict(checkpoint['model'])\n",
    "print(args.model_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4818097f-1374-43eb-833d-86393e82aa11",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def prediction_val(model_s,model_g,model_stat,model,loss_fn,train_dataloader):\n",
    "    model_s.eval()\n",
    "    model_g.eval()\n",
    "    model_stat.eval()\n",
    "    model.eval()\n",
    "\n",
    "\n",
    "    losses = 0\n",
    "    correct = 0\n",
    "    preds = []\n",
    "    idxs = []\n",
    "    labels = []\n",
    "    outs= []\n",
    "    trip_idxs = []\n",
    "    with torch.no_grad():\n",
    "        for data_sensor,data_gps,stat_sensors,stat_gps,stat_road, label,idx,trip_idx, lengths in train_dataloader:\n",
    "            data_sensor = data_sensor.to(args.device)\n",
    "            data_gps = data_gps.to(args.device)\n",
    "            stat_sensors,stat_gps,stat_road = stat_sensors.to(args.device),stat_gps.to(args.device),stat_road.to(args.device)\n",
    "            label = label.to(args.device)[:,(args.L1-1):]\n",
    "\n",
    "            output_s = model_s(data_sensor)\n",
    "            output_g = model_g(data_gps)\n",
    "            output_stat = model_stat(stat_sensors,stat_gps,stat_road)\n",
    "            out = model(torch.cat([output_s,output_g,output_stat],dim=-1),lengths)\n",
    "\n",
    "            loss = loss_fn( out.reshape(-1, out.shape[-1]), label.reshape(-1))\n",
    "\n",
    "            losses += loss.item() \n",
    "\n",
    "            mask = label ==args.pad_value\n",
    "            pred = torch.argmax(out, dim=2)\n",
    "            correct +=  (pred ==label ).masked_fill(mask,0).sum().item() / (~mask).sum()\n",
    "\n",
    "            preds.append(pred)\n",
    "            idxs.append(idx[:,(args.L1-1):])\n",
    "            labels.append(label)\n",
    "            outs.append(F.softmax(out,dim=-1))\n",
    "            trip_idxs.append(trip_idx)\n",
    "\n",
    "    model_s.train()\n",
    "    model_g.train()\n",
    "    model.train()\n",
    "    model_stat.train()\n",
    "    return torch.cat(preds),torch.cat(idxs),torch.cat(trip_idxs),torch.cat(labels),torch.cat(outs),losses / len(train_dataloader),correct/len(train_dataloader)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13357ccf-c66b-4828-b7b6-fdb0920c396d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss 0.7691177040338516 test acc 0.8454403281211853\n",
      "acc_pred 0.8579065271855568\n",
      "acc_outs 0.8616122211133831\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Still       0.93      0.94      0.93     29676\n",
      "        Walk       0.95      0.95      0.95     25879\n",
      "         Run       0.98      1.00      0.99      2754\n",
      "        Bike       0.81      0.82      0.82     12001\n",
      "         Car       1.00      0.40      0.57     20438\n",
      "         Bus       0.38      0.88      0.53      9138\n",
      "       Train       1.00      0.97      0.99     21763\n",
      "      Subway       0.95      0.98      0.96     21644\n",
      "\n",
      "    accuracy                           0.86    143293\n",
      "   macro avg       0.88      0.87      0.84    143293\n",
      "weighted avg       0.91      0.86      0.86    143293\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def val_dataset(loc='Hand'):\n",
    "\n",
    "\n",
    "    train_hand = pd.read_pickle('/DATA2/lvxiaoling/limengyuan/SHL2023/valid/Hand/raw_data.pkl')\n",
    "    stat_data = pd.read_pickle('/DATA2/lvxiaoling/limengyuan/SHL2023/valid/Hand/data.pkl').fillna(0).drop_duplicates(keep='first')   \n",
    "\n",
    "    data_x = np.arange(len(train_hand[0]))#trajectory id\n",
    "    data_y = [int(i[0][0,-4]) for i in train_hand[1]]\n",
    "    val_sensor = [j for i in data_x for j in train_hand[0][i]]\n",
    "    val_gps = [j for i in data_x for j in train_hand[1][i]]\n",
    "    val_data = dset(val_sensor,val_gps,stat_data)\n",
    "\n",
    "\n",
    "    test_loader1 = torch.utils.data.DataLoader(\n",
    "        dataset=val_data,\n",
    "        batch_size=args.batch_size,\n",
    "        shuffle=False,\n",
    "        collate_fn=collate_batch,\n",
    "        num_workers = args.num_workers\n",
    "        )\n",
    "    return test_loader1\n",
    "val_loader = val_dataset(loc='Hand')\n",
    "\n",
    "\n",
    "test_loss,test_acc  = evaluate(model_s,model_g,model_stat,model, criterion, val_loader)\n",
    "print('test loss',test_loss,'test acc',test_acc.item())\n",
    "\n",
    "\n",
    "preds,idxs,trip_idxs,labels,outs,_,_ = prediction_val(model_s,model_g,model_stat,model, criterion, val_loader)\n",
    "\n",
    "\n",
    "idxs_1 = idxs.reshape(-1,1).cpu().numpy()\n",
    "labels_1 = labels.reshape(-1,1).cpu().numpy()\n",
    "preds_1 = preds.reshape(-1,1).cpu().numpy()\n",
    "outs_1 = outs.reshape(-1,outs.shape[2]).cpu().numpy()\n",
    "\n",
    "results = pd.DataFrame(np.concatenate((idxs_1,labels_1,preds_1,outs_1), axis =1))\n",
    "results.columns = ['idx','label_true','preds'] + [i for i in range(8)]\n",
    "\n",
    "\n",
    "#results_new = results.groupby('id')[[i for i in range(8)]].mean()\n",
    "results_new = results.groupby('idx')[['label_true']].min().reset_index().astype(int)\n",
    "results_new['preds'] = results.groupby('idx')[['preds']].agg(lambda x: x.value_counts().index[0]).values.astype(int)\n",
    "results_new[['out_{}'.format(i) for i in range(8)]] = results.groupby('idx')[[i for i in range(8)]].mean().values\n",
    "results_new['out_pred'] = results_new[['out_{}'.format(i) for i in range(8)]].idxmax(axis=1).str.replace('out_','').astype(int).values\n",
    "\n",
    "\n",
    "results_new = results_new[results_new['idx']>=0]\n",
    "print('acc_pred',(results_new['label_true']==results_new['preds']).mean())\n",
    "print('acc_outs',(results_new['label_true']==results_new['out_pred']).mean())\n",
    "\n",
    "\n",
    "y_true = results_new['label_true']\n",
    "y_pred = results_new['out_pred']\n",
    "label_sort = ['Still','Walk','Run','Bike','Car','Bus','Train', 'Subway']\n",
    "print(classification_report(y_true, y_pred, target_names = label_sort))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2730a684",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8429934120478508\n"
     ]
    }
   ],
   "source": [
    "f1 = f1_score(y_true, y_pred, average='macro')\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "08a8c71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_new.to_pickle('/DATA2/lvxiaoling/limengyuan/SHL2023/out_put2/val_dl2.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33588cd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6672b08b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df79c43c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e7cda8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5687d929-96b6-4b50-b5d9-3c736e0b0f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.read_pickle('/DATA2/lvxiaoling/limengyuan/SHL2023/valid/Hand/data_m.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "523b0cb5-fad3-4e6f-8b0e-e4f8a32a7c2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>label_true</th>\n",
       "      <th>preds</th>\n",
       "      <th>out_0</th>\n",
       "      <th>out_1</th>\n",
       "      <th>out_2</th>\n",
       "      <th>out_3</th>\n",
       "      <th>out_4</th>\n",
       "      <th>out_5</th>\n",
       "      <th>out_6</th>\n",
       "      <th>out_7</th>\n",
       "      <th>out_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>972</th>\n",
       "      <td>98151959</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6.812557e-10</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.999497</td>\n",
       "      <td>4.834754e-04</td>\n",
       "      <td>3.061111e-06</td>\n",
       "      <td>1.079840e-08</td>\n",
       "      <td>6.627248e-09</td>\n",
       "      <td>7.514964e-11</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>973</th>\n",
       "      <td>98152059</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.117635e-09</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.999392</td>\n",
       "      <td>5.822952e-04</td>\n",
       "      <td>3.624860e-06</td>\n",
       "      <td>1.461321e-08</td>\n",
       "      <td>7.341805e-09</td>\n",
       "      <td>1.216021e-10</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>974</th>\n",
       "      <td>98152159</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.428232e-09</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.999253</td>\n",
       "      <td>7.084942e-04</td>\n",
       "      <td>4.146106e-06</td>\n",
       "      <td>1.660578e-08</td>\n",
       "      <td>7.957381e-09</td>\n",
       "      <td>1.642354e-10</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>975</th>\n",
       "      <td>98152259</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.738339e-09</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.999216</td>\n",
       "      <td>7.321134e-04</td>\n",
       "      <td>4.364371e-06</td>\n",
       "      <td>1.686876e-08</td>\n",
       "      <td>7.958896e-09</td>\n",
       "      <td>1.999083e-10</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>976</th>\n",
       "      <td>98152359</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.895418e-09</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>0.999245</td>\n",
       "      <td>6.913923e-04</td>\n",
       "      <td>4.295467e-06</td>\n",
       "      <td>1.617337e-08</td>\n",
       "      <td>6.955311e-09</td>\n",
       "      <td>2.326166e-10</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130332</th>\n",
       "      <td>111147513</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.754528e-01</td>\n",
       "      <td>0.821100</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>3.233377e-07</td>\n",
       "      <td>3.206798e-11</td>\n",
       "      <td>4.019823e-08</td>\n",
       "      <td>3.440872e-03</td>\n",
       "      <td>3.214815e-07</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130333</th>\n",
       "      <td>111147613</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.537386e-01</td>\n",
       "      <td>0.842450</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>3.394254e-07</td>\n",
       "      <td>3.330260e-11</td>\n",
       "      <td>3.256310e-08</td>\n",
       "      <td>3.804275e-03</td>\n",
       "      <td>2.659943e-07</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130334</th>\n",
       "      <td>111147713</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.680085e-01</td>\n",
       "      <td>0.826683</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>3.873066e-07</td>\n",
       "      <td>4.646695e-11</td>\n",
       "      <td>2.810959e-08</td>\n",
       "      <td>5.300879e-03</td>\n",
       "      <td>2.992055e-07</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130335</th>\n",
       "      <td>111147813</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.387138e-01</td>\n",
       "      <td>0.753047</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>3.962014e-07</td>\n",
       "      <td>6.450293e-11</td>\n",
       "      <td>3.752051e-08</td>\n",
       "      <td>8.231108e-03</td>\n",
       "      <td>3.968620e-07</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130336</th>\n",
       "      <td>111147913</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.064511e-01</td>\n",
       "      <td>0.677377</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>3.150029e-07</td>\n",
       "      <td>9.503134e-11</td>\n",
       "      <td>5.764248e-08</td>\n",
       "      <td>1.616381e-02</td>\n",
       "      <td>5.163662e-07</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26037 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              idx  label_true  preds         out_0     out_1     out_2  \\\n",
       "972      98151959           2      2  6.812557e-10  0.000016  0.999497   \n",
       "973      98152059           2      2  1.117635e-09  0.000022  0.999392   \n",
       "974      98152159           2      2  1.428232e-09  0.000035  0.999253   \n",
       "975      98152259           2      2  1.738339e-09  0.000047  0.999216   \n",
       "976      98152359           2      2  1.895418e-09  0.000059  0.999245   \n",
       "...           ...         ...    ...           ...       ...       ...   \n",
       "130332  111147513           0      1  1.754528e-01  0.821100  0.000005   \n",
       "130333  111147613           0      1  1.537386e-01  0.842450  0.000006   \n",
       "130334  111147713           0      1  1.680085e-01  0.826683  0.000007   \n",
       "130335  111147813           0      1  2.387138e-01  0.753047  0.000007   \n",
       "130336  111147913           0      1  3.064511e-01  0.677377  0.000008   \n",
       "\n",
       "               out_3         out_4         out_5         out_6         out_7  \\\n",
       "972     4.834754e-04  3.061111e-06  1.079840e-08  6.627248e-09  7.514964e-11   \n",
       "973     5.822952e-04  3.624860e-06  1.461321e-08  7.341805e-09  1.216021e-10   \n",
       "974     7.084942e-04  4.146106e-06  1.660578e-08  7.957381e-09  1.642354e-10   \n",
       "975     7.321134e-04  4.364371e-06  1.686876e-08  7.958896e-09  1.999083e-10   \n",
       "976     6.913923e-04  4.295467e-06  1.617337e-08  6.955311e-09  2.326166e-10   \n",
       "...              ...           ...           ...           ...           ...   \n",
       "130332  3.233377e-07  3.206798e-11  4.019823e-08  3.440872e-03  3.214815e-07   \n",
       "130333  3.394254e-07  3.330260e-11  3.256310e-08  3.804275e-03  2.659943e-07   \n",
       "130334  3.873066e-07  4.646695e-11  2.810959e-08  5.300879e-03  2.992055e-07   \n",
       "130335  3.962014e-07  6.450293e-11  3.752051e-08  8.231108e-03  3.968620e-07   \n",
       "130336  3.150029e-07  9.503134e-11  5.764248e-08  1.616381e-02  5.163662e-07   \n",
       "\n",
       "        out_pred  \n",
       "972            2  \n",
       "973            2  \n",
       "974            2  \n",
       "975            2  \n",
       "976            2  \n",
       "...          ...  \n",
       "130332         1  \n",
       "130333         1  \n",
       "130334         1  \n",
       "130335         1  \n",
       "130336         1  \n",
       "\n",
       "[26037 rows x 12 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = results_new[results_new['idx'].isin(a['idx'])]\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "93ce747b-a7fe-4a88-b593-fe31a94f030e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Still       0.96      0.94      0.95      3661\n",
      "        Walk       0.93      1.00      0.96      3743\n",
      "         Run       1.00      1.00      1.00       310\n",
      "        Bike       1.00      1.00      1.00      1840\n",
      "         Car       1.00      0.89      0.94      6710\n",
      "         Bus       0.30      1.00      0.47       236\n",
      "       Train       1.00      1.00      1.00      7370\n",
      "      Subway       1.00      1.00      1.00      2167\n",
      "\n",
      "    accuracy                           0.96     26037\n",
      "   macro avg       0.90      0.98      0.91     26037\n",
      "weighted avg       0.98      0.96      0.97     26037\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(m['label_true'].values, m['out_pred'].values, target_names = label_sort))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b1e7fc89-9681-4adc-99f9-8e4df556b0dc",
   "metadata": {},
   "source": [
    "# 加载原始的训练集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9b3822aa-6dc5-4640-b10f-9fdf7503dac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss 0.06333301598226235 test acc 0.991351842880249\n"
     ]
    }
   ],
   "source": [
    "def val_dataset(loc='Hand'):\n",
    "\n",
    "\n",
    "    train_hand = cPickle.load(open('/DATA2/lvxiaoling/limengyuan/SHL2023/train/{}/raw_data_m.pkl'.format(loc),'rb'))\n",
    "    stat_data = cPickle.load(open('/DATA2/lvxiaoling/limengyuan/SHL2023/train/{}/data_m.pkl'.format(loc),'rb')).fillna(0).drop_duplicates(keep='first')   \n",
    "\n",
    "    data_x = np.arange(len(train_hand[0]))#trajectory id\n",
    "    data_y = [int(i[0][0,-4]) for i in train_hand[1]]\n",
    "    val_sensor = [j for i in data_x for j in train_hand[0][i]]\n",
    "    val_gps = [j for i in data_x for j in train_hand[1][i]]\n",
    "    val_data = dset(val_sensor,val_gps,stat_data)\n",
    "\n",
    "\n",
    "    test_loader1 = torch.utils.data.DataLoader(\n",
    "        dataset=val_data,\n",
    "        batch_size=args.batch_size,\n",
    "        shuffle=False,\n",
    "        collate_fn=collate_batch,\n",
    "        num_workers = args.num_workers\n",
    "        )\n",
    "    return test_loader1\n",
    "val_loader = val_dataset(loc='Hand')\n",
    "\n",
    "\n",
    "test_loss,test_acc  = evaluate(model_s,model_g,model_stat,model, criterion, val_loader)\n",
    "print('test loss',test_loss,'test acc',test_acc.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5fc3673b-a4c3-462e-b5cb-73d2803edcf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc_outs 0.991591031742138\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Still       1.00      0.98      0.99    120940\n",
      "        Walk       0.99      1.00      1.00    117175\n",
      "         Run       1.00      0.95      0.98     35805\n",
      "        Bike       0.98      1.00      0.99    110793\n",
      "         Car       1.00      1.00      1.00    146300\n",
      "         Bus       1.00      1.00      1.00    121841\n",
      "       Train       0.99      0.99      0.99    147554\n",
      "      Subway       0.98      0.99      0.99    116827\n",
      "\n",
      "    accuracy                           0.99    917235\n",
      "   macro avg       0.99      0.99      0.99    917235\n",
      "weighted avg       0.99      0.99      0.99    917235\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds,idxs,trip_idxs,labels,outs,_,_ = prediction_val(model_s,model_g,model_stat,model, criterion, val_loader)\n",
    "\n",
    "idxs_1 = idxs.reshape(-1,1).cpu().numpy()\n",
    "labels_1 = labels.reshape(-1,1).cpu().numpy()\n",
    "preds_1 = preds.reshape(-1,1).cpu().numpy()\n",
    "outs_1 = outs.reshape(-1,outs.shape[2]).cpu().numpy()\n",
    "\n",
    "results = pd.DataFrame(np.concatenate((idxs_1,labels_1,preds_1,outs_1), axis =1))\n",
    "results.columns = ['idx','label_true','preds'] + [i for i in range(8)]\n",
    "\n",
    "\n",
    "#results_new = results.groupby('id')[[i for i in range(8)]].mean()\n",
    "results_new = results.groupby('idx')[['label_true']].min().reset_index().astype(int)\n",
    "results_new[['out_{}'.format(i) for i in range(8)]] = results.groupby('idx')[[i for i in range(8)]].mean().values\n",
    "results_new['out_pred'] = results_new[['out_{}'.format(i) for i in range(8)]].idxmax(axis=1).str.replace('out_','').astype(int).values\n",
    "\n",
    "\n",
    "results_new = results_new[results_new['idx']>=0]\n",
    "print('acc_outs',(results_new['label_true']==results_new['out_pred']).mean())\n",
    "results_new.to_pickle('/DATA2/lvxiaoling/limengyuan/SHL2023/out_put/train_dl2.pkl')\n",
    "\n",
    "\n",
    "y_true = results_new['label_true']\n",
    "y_pred = results_new['out_pred']\n",
    "label_sort = ['Still','Walk','Run','Bike','Car','Bus','Train', 'Subway']\n",
    "print(classification_report(y_true, y_pred, target_names = label_sort))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0cfb5f9b-d56a-4777-96f1-6ef4840c1710",
   "metadata": {},
   "source": [
    "# 加载原始验证集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e4f415f6-cbb6-41d8-b0e8-c45ad8c6ab37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss 0.6045635119080544 test acc 0.9281517863273621\n"
     ]
    }
   ],
   "source": [
    "def val_dataset(loc='Hand'):\n",
    "\n",
    "\n",
    "    train_hand = cPickle.load(open('/DATA2/lvxiaoling/limengyuan/SHL2023/valid/{}/raw_data_m.pkl'.format(loc),'rb'))\n",
    "    stat_data = cPickle.load(open('/DATA2/lvxiaoling/limengyuan/SHL2023/valid/{}/data_m.pkl'.format(loc),'rb')).fillna(0).drop_duplicates(keep='first')   \n",
    "\n",
    "    data_x = np.arange(len(train_hand[0]))#trajectory id\n",
    "    data_y = [int(i[0][0,-4]) for i in train_hand[1]]\n",
    "    val_sensor = [j for i in data_x for j in train_hand[0][i]]\n",
    "    val_gps = [j for i in data_x for j in train_hand[1][i]]\n",
    "    val_data = dset(val_sensor,val_gps,stat_data)\n",
    "\n",
    "\n",
    "    test_loader1 = torch.utils.data.DataLoader(\n",
    "        dataset=val_data,\n",
    "        batch_size=args.batch_size,\n",
    "        shuffle=False,\n",
    "        collate_fn=collate_batch,\n",
    "        num_workers = args.num_workers\n",
    "        )\n",
    "    return test_loader1\n",
    "val_loader = val_dataset(loc='Hand')\n",
    "\n",
    "\n",
    "test_loss,test_acc  = evaluate(model_s,model_g,model_stat,model, criterion, val_loader)\n",
    "print('test loss',test_loss,'test acc',test_acc.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "752265ed-f946-422d-afa4-66e2315985d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc_outs 0.9332412002222998\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Still       0.99      0.96      0.98     30422\n",
      "        Walk       0.95      1.00      0.97     30804\n",
      "         Run       1.00      0.86      0.93      9000\n",
      "        Bike       0.99      0.99      0.99     18040\n",
      "         Car       0.81      0.94      0.87     32418\n",
      "         Bus       0.92      0.71      0.81     28475\n",
      "       Train       1.00      0.97      0.98     30079\n",
      "      Subway       0.90      1.00      0.95     24091\n",
      "\n",
      "    accuracy                           0.93    203329\n",
      "   macro avg       0.95      0.93      0.93    203329\n",
      "weighted avg       0.94      0.93      0.93    203329\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds,idxs,trip_idxs,labels,outs,_,_ = prediction_val(model_s,model_g,model_stat,model, criterion, val_loader)\n",
    "\n",
    "idxs_1 = idxs.reshape(-1,1).cpu().numpy()\n",
    "labels_1 = labels.reshape(-1,1).cpu().numpy()\n",
    "preds_1 = preds.reshape(-1,1).cpu().numpy()\n",
    "outs_1 = outs.reshape(-1,outs.shape[2]).cpu().numpy()\n",
    "\n",
    "results = pd.DataFrame(np.concatenate((idxs_1,labels_1,preds_1,outs_1), axis =1))\n",
    "results.columns = ['idx','label_true','preds'] + [i for i in range(8)]\n",
    "\n",
    "\n",
    "#results_new = results.groupby('id')[[i for i in range(8)]].mean()\n",
    "results_new = results.groupby('idx')[['label_true']].min().reset_index().astype(int)\n",
    "results_new[['out_{}'.format(i) for i in range(8)]] = results.groupby('idx')[[i for i in range(8)]].mean().values\n",
    "results_new['out_pred'] = results_new[['out_{}'.format(i) for i in range(8)]].idxmax(axis=1).str.replace('out_','').astype(int).values\n",
    "\n",
    "\n",
    "results_new = results_new[results_new['idx']>=0]\n",
    "print('acc_outs',(results_new['label_true']==results_new['out_pred']).mean())\n",
    "results_new.to_pickle('/DATA2/lvxiaoling/limengyuan/SHL2023/out_put/val_dl2.pkl')\n",
    "\n",
    "\n",
    "y_true = results_new['label_true']\n",
    "y_pred = results_new['out_pred']\n",
    "label_sort = ['Still','Walk','Run','Bike','Car','Bus','Train', 'Subway']\n",
    "print(classification_report(y_true, y_pred, target_names = label_sort))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a52c6908-2b23-40bc-b83c-1f1760d83ff1",
   "metadata": {},
   "source": [
    "# 加载原始测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fb472de6-af4e-4660-99de-c1b8dc526736",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss 0.0 test acc nan\n"
     ]
    }
   ],
   "source": [
    "def val_dataset(loc='Hand'):\n",
    "\n",
    "\n",
    "    train_hand = cPickle.load(open('/DATA2/lvxiaoling/limengyuan/SHL2023/test/raw_data.pkl'.format(loc),'rb'))\n",
    "    stat_data = cPickle.load(open('/DATA2/lvxiaoling/limengyuan/SHL2023/test/data.pkl'.format(loc),'rb')).fillna(0).drop_duplicates(keep='first')   \n",
    "\n",
    "    data_x = np.arange(len(train_hand[0]))#trajectory id\n",
    "    data_y = [int(i[0][0,-4]) for i in train_hand[1]]\n",
    "    val_sensor = [j for i in data_x for j in train_hand[0][i]]\n",
    "    val_gps = [j for i in data_x for j in train_hand[1][i]]\n",
    "    val_data = dset(val_sensor,val_gps,stat_data)\n",
    "\n",
    "\n",
    "    test_loader1 = torch.utils.data.DataLoader(\n",
    "        dataset=val_data,\n",
    "        batch_size=args.batch_size,\n",
    "        shuffle=False,\n",
    "        collate_fn=collate_batch,\n",
    "        num_workers = args.num_workers\n",
    "        )\n",
    "    return test_loader1\n",
    "val_loader = val_dataset(loc='Hand')\n",
    "\n",
    "\n",
    "test_loss,test_acc  = evaluate(model_s,model_g,model_stat,model, criterion, val_loader)\n",
    "print('test loss',test_loss,'test acc',test_acc.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f053b20f-f561-4e76-9380-5fa210f3832c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc_outs 0.0\n"
     ]
    }
   ],
   "source": [
    "preds,idxs,trip_idxs,labels,outs,_,_ = prediction_val(model_s,model_g,model_stat,model, criterion, val_loader)\n",
    "\n",
    "idxs_1 = idxs.reshape(-1,1).cpu().numpy()\n",
    "labels_1 = labels.reshape(-1,1).cpu().numpy()\n",
    "preds_1 = preds.reshape(-1,1).cpu().numpy()\n",
    "outs_1 = outs.reshape(-1,outs.shape[2]).cpu().numpy()\n",
    "\n",
    "results = pd.DataFrame(np.concatenate((idxs_1,labels_1,preds_1,outs_1), axis =1))\n",
    "results.columns = ['idx','label_true','preds'] + [i for i in range(8)]\n",
    "\n",
    "\n",
    "#results_new = results.groupby('id')[[i for i in range(8)]].mean()\n",
    "results_new = results.groupby('idx')[['label_true']].min().reset_index().astype(int)\n",
    "results_new[['out_{}'.format(i) for i in range(8)]] = results.groupby('idx')[[i for i in range(8)]].mean().values\n",
    "results_new['out_pred'] = results_new[['out_{}'.format(i) for i in range(8)]].idxmax(axis=1).str.replace('out_','').astype(int).values\n",
    "\n",
    "\n",
    "results_new = results_new[results_new['idx']>=0]\n",
    "\n",
    "results_new.to_pickle('/DATA2/lvxiaoling/limengyuan/SHL2023/out_put/test_dl2.pkl')\n",
    "\n",
    "print('acc_outs',(results_new['label_true']==results_new['out_pred']).mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2135c49d-027d-4e34-a718-b3d300fd2910",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "       5, 5])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = 400\n",
    "results_new['out_pred'].values[m:m+200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "04d87e5c-f6fe-4f6e-9944-deefd14a0739",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1         3\n",
       "2         3\n",
       "3         3\n",
       "4         3\n",
       "5         3\n",
       "         ..\n",
       "462266    1\n",
       "462267    1\n",
       "462268    1\n",
       "462269    1\n",
       "462270    1\n",
       "Name: out_pred, Length: 462270, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_new['out_pred']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a883bbd-27c9-4fe4-b5f1-668993aca7f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yangyixia",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
